{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Audiomentations documentation A Python library for audio data augmentation. Inspired by albumentations . Useful for deep learning. Runs on CPU. Supports mono audio and multichannel audio . Can be integrated in training pipelines in e.g. Tensorflow/Keras or Pytorch. Has helped people get world-class results in Kaggle competitions. Is used by companies making next-generation audio products. Need a Pytorch-specific alternative with GPU support? Check out torch-audiomentations ! Setup pip install audiomentations Optional requirements Some features have extra dependencies. Extra python package dependencies can be installed by running pip install audiomentations[extras] Feature Extra dependencies Limiter cylimiter LoudnessNormalization pyloudnorm Mp3Compression ffmpeg and [ pydub or lameenc ] RoomSimulator pyroomacoustics Note: ffmpeg can be installed via e.g. conda or from the official ffmpeg download page . Usage example Waveform from audiomentations import Compose , AddGaussianNoise , TimeStretch , PitchShift , Shift import numpy as np augment = Compose ([ AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 0.5 ), TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , p = 0.5 ), PitchShift ( min_semitones =- 4 , max_semitones = 4 , p = 0.5 ), Shift ( min_fraction =- 0.5 , max_fraction = 0.5 , p = 0.5 ), ]) # Generate 2 seconds of dummy audio for the sake of example samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) # Augment/transform/perturb the audio data augmented_samples = augment ( samples = samples , sample_rate = 16000 ) Check out the source code at audiomentations/augmentations/ to see the waveform transforms you can apply, and what arguments they have. Spectrogram from audiomentations import SpecCompose , SpecChannelShuffle , SpecFrequencyMask import numpy as np augment = SpecCompose ( [ SpecChannelShuffle ( p = 0.5 ), SpecFrequencyMask ( p = 0.5 ), ] ) # Example spectrogram with 1025 frequency bins, 256 time steps and 2 audio channels spectrogram = np . random . random (( 1025 , 256 , 2 )) # Augment/transform/perturb the spectrogram augmented_spectrogram = augment ( spectrogram ) See audiomentations/spec_augmentations/spectrogram_transforms.py for spectrogram transforms. Waveform transforms For a list and explanation of all waveform transforms, see Waveform transforms in the menu. Waveform transforms can be visualized (for understanding) by the audio-transformation-visualization GUI (made by phrasenmaeher ), where you can upload your own input wav file Spectrogram transforms For a list and brief explanation of all spectrogram transforms, see Spectrogram transforms Composition classes Compose Compose applies the given sequence of transforms when called, optionally shuffling the sequence for every call. SpecCompose Same as Compose, but for spectrogram transforms OneOf OneOf randomly picks one of the given transforms when called, and applies that transform. SomeOf SomeOf randomly picks several of the given transforms when called, and applies those transforms. Known limitations A few transforms do not support multichannel audio yet. See Multichannel audio Expects the input dtype to be float32, and have values between -1 and 1. The code runs on CPU, not GPU. For a GPU-compatible version, check out pytorch-audiomentations Multiprocessing probably works but is not officially supported yet Contributions are welcome! Multichannel audio As of v0.22.0, all transforms except AddBackgroundNoise and AddShortNoises support not only mono audio (1-dimensional numpy arrays), but also stereo audio, i.e. 2D arrays with shape like (num_channels, num_samples) Acknowledgements Thanks to Nomono for backing audiomentations. Thanks to all contributors who help improving audiomentations.","title":"Home"},{"location":"#audiomentations-documentation","text":"A Python library for audio data augmentation. Inspired by albumentations . Useful for deep learning. Runs on CPU. Supports mono audio and multichannel audio . Can be integrated in training pipelines in e.g. Tensorflow/Keras or Pytorch. Has helped people get world-class results in Kaggle competitions. Is used by companies making next-generation audio products. Need a Pytorch-specific alternative with GPU support? Check out torch-audiomentations !","title":"Audiomentations documentation"},{"location":"#setup","text":"pip install audiomentations","title":"Setup"},{"location":"#optional-requirements","text":"Some features have extra dependencies. Extra python package dependencies can be installed by running pip install audiomentations[extras] Feature Extra dependencies Limiter cylimiter LoudnessNormalization pyloudnorm Mp3Compression ffmpeg and [ pydub or lameenc ] RoomSimulator pyroomacoustics Note: ffmpeg can be installed via e.g. conda or from the official ffmpeg download page .","title":"Optional requirements"},{"location":"#usage-example","text":"","title":"Usage example"},{"location":"#waveform","text":"from audiomentations import Compose , AddGaussianNoise , TimeStretch , PitchShift , Shift import numpy as np augment = Compose ([ AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 0.5 ), TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , p = 0.5 ), PitchShift ( min_semitones =- 4 , max_semitones = 4 , p = 0.5 ), Shift ( min_fraction =- 0.5 , max_fraction = 0.5 , p = 0.5 ), ]) # Generate 2 seconds of dummy audio for the sake of example samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) # Augment/transform/perturb the audio data augmented_samples = augment ( samples = samples , sample_rate = 16000 ) Check out the source code at audiomentations/augmentations/ to see the waveform transforms you can apply, and what arguments they have.","title":"Waveform"},{"location":"#spectrogram","text":"from audiomentations import SpecCompose , SpecChannelShuffle , SpecFrequencyMask import numpy as np augment = SpecCompose ( [ SpecChannelShuffle ( p = 0.5 ), SpecFrequencyMask ( p = 0.5 ), ] ) # Example spectrogram with 1025 frequency bins, 256 time steps and 2 audio channels spectrogram = np . random . random (( 1025 , 256 , 2 )) # Augment/transform/perturb the spectrogram augmented_spectrogram = augment ( spectrogram ) See audiomentations/spec_augmentations/spectrogram_transforms.py for spectrogram transforms.","title":"Spectrogram"},{"location":"#waveform-transforms","text":"For a list and explanation of all waveform transforms, see Waveform transforms in the menu. Waveform transforms can be visualized (for understanding) by the audio-transformation-visualization GUI (made by phrasenmaeher ), where you can upload your own input wav file","title":"Waveform transforms"},{"location":"#spectrogram-transforms","text":"For a list and brief explanation of all spectrogram transforms, see Spectrogram transforms","title":"Spectrogram transforms"},{"location":"#composition-classes","text":"","title":"Composition classes"},{"location":"#compose","text":"Compose applies the given sequence of transforms when called, optionally shuffling the sequence for every call.","title":"Compose"},{"location":"#speccompose","text":"Same as Compose, but for spectrogram transforms","title":"SpecCompose"},{"location":"#oneof","text":"OneOf randomly picks one of the given transforms when called, and applies that transform.","title":"OneOf"},{"location":"#someof","text":"SomeOf randomly picks several of the given transforms when called, and applies those transforms.","title":"SomeOf"},{"location":"#known-limitations","text":"A few transforms do not support multichannel audio yet. See Multichannel audio Expects the input dtype to be float32, and have values between -1 and 1. The code runs on CPU, not GPU. For a GPU-compatible version, check out pytorch-audiomentations Multiprocessing probably works but is not officially supported yet Contributions are welcome!","title":"Known limitations"},{"location":"#multichannel-audio","text":"As of v0.22.0, all transforms except AddBackgroundNoise and AddShortNoises support not only mono audio (1-dimensional numpy arrays), but also stereo audio, i.e. 2D arrays with shape like (num_channels, num_samples)","title":"Multichannel audio"},{"location":"#acknowledgements","text":"Thanks to Nomono for backing audiomentations. Thanks to all contributors who help improving audiomentations.","title":"Acknowledgements"},{"location":"alternatives/","text":"Alternatives Audiomentations isn't the only python library that can do various types of audio data augmentation/degradation! Here's an overview: Name Github stars License Last commit GPU support? audio-degradation-toolbox audio_degrader audiomentations AugLy kapre muda nlpaug pedalboard pydiogment python-audio-effects sigment SpecAugment spec_augment teal torch-audiomentations torchaudio-augmentations WavAugment","title":"Alternatives"},{"location":"alternatives/#alternatives","text":"Audiomentations isn't the only python library that can do various types of audio data augmentation/degradation! Here's an overview: Name Github stars License Last commit GPU support? audio-degradation-toolbox audio_degrader audiomentations AugLy kapre muda nlpaug pedalboard pydiogment python-audio-effects sigment SpecAugment spec_augment teal torch-audiomentations torchaudio-augmentations WavAugment","title":"Alternatives"},{"location":"changelog/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . 0.29.0 - 2023-03-15 Added Add apply_to parameter that can be set to \"only_too_loud_sounds\" in Normalize Changed Change default value of noise_rms from \"relative\" to \"relative_to_whole_input\" in AddShortNoises Change default values of min_snr_in_db (from 0.0 to -6.0 ), max_snr_in_db (from 24.0 to 18.0 ), min_time_between_sounds (from 4.0 to 2.0 ) and max_time_between_sounds (from 16.0 to 8.0 ) in AddShortNoises Fixed Fix a bug where Limiter raised an exception when it got digital silence as input 0.28.0 - 2023-01-12 Added Add/improve type hints Add/improve documentation Fixed Fix a bug in RoomSimulator where the value of max_order was not respected Removed Remove FrequencyMask that had been deprecated since version 0.22.0. BandStopFilter is a good alternative. 0.27.0 - 2022-09-13 Changed Speed up Limiter by ~8x Fix/improve some docstrings and type hints Change default values in Trim and ApplyImpulseResponse according to the warnings that were added in v0.23.0 Emit a FutureWarning when noise_rms in AddShortNoises is not specified - the default value will change from \"relative\" to \"relative_to_whole_input\" in a future version. 0.26.0 - 2022-08-19 Added Add new transform Lambda . Thanks to Thanatoz-1. Add new transform Limiter . Thanks to pzelasko. Fixed Fix incorrect type hints in RoomSimulator Make Shift robust to different sample rate inputs when parameters are frozen 0.25.1 - 2022-06-15 Fixed Fix a bug where RoomSimulator would treat an x value as if it was y, and vice versa 0.25.0 - 2022-05-30 Added Add AirAbsorption transform Add mp4 to the list of recognized audio filename extensions Changed Guard against invalid params in TimeMask Emit FutureWarning instead of UserWarning in Trim and ApplyImpulseResponse Allow specifying a file path, a folder path, a list of files or a list of folders to ApplyImpulseResponse , AddBackgroundNoise and AddShortNoises . Previously only a path to a folder was allowed. Fixed Fix a bug with noise_transform in AddBackgroundNoise where some SNR calculations were done before the noise_transform was applied. This has sometimes led to incorrect SNR in the output. This changes the behavior of AddBackgroundNoise (when noise_transform is used). Removed Remove support for Python 3.6, as it is past its end of life already. RIP. 0.24.0 - 2022-03-18 Added Add SevenBandParametricEQ transform Add optional noise_transform in AddShortNoises Add .aac and .aif to the list of recognized audio filename endings Changed Show warning if top_db and/or p in Trim are not specified because their default values will change in a future version Fixed Fix filter instability bug related to center freq above nyquist freq in LowShelfFilter and HighShelfFilter 0.23.0 - 2022-03-07 Added Add Padding transform Add RoomSimulator transform for simulating shoebox rooms using pyroomacoustics Add parameter signal_gain_in_db_during_noise in AddShortNoises Changed Not specifying a value for leave_length_unchanged in AddImpulseResponse now emits a warning, as the default value will change from False to True in a future version. Removed Remove the deprecated AddImpulseResponse alias. Use ApplyImpulseResponse instead. Remove support for the legacy parameters min_SNR and max_SNR in AddGaussianSNR Remove useless default path value in AddBackgroundNoise , AddShortNoises and ApplyImpulseResponse 0.22.0 - 2022-02-18 Added Implement GainTransition Add support for librosa 0.9 Add support for stereo audio in Mp3Compression , Resample and Trim Add \"relative_to_whole_input\" option for noise_rms parameter in AddShortNoises Add optional noise_transform in AddBackgroundNoise Changed Improve speed of PitchShift by 6-18% when the input audio is stereo Deprecated Deprecate FrequencyMask in favor of BandStopFilter Removed Remove support for librosa<=0.7.2 0.21.0 - 2022-02-10 Added Add support for multichannel audio in ApplyImpulseResponse , BandPassFilter , HighPassFilter and LowPassFilter Add BandStopFilter (similar to FrequencyMask, but with overhauled defaults and parameter randomization behavior), PeakingFilter , LowShelfFilter and HighShelfFilter Add parameter add_all_noises_with_same_level in AddShortNoises Changed Change BandPassFilter , LowPassFilter , HighPassFilter , to use scipy's butterworth filters instead of pydub. Now they have parametrized roll-off. Filters are now steeper than before by default - set min_rolloff=6, max_rolloff=6 to get the old behavior. They also support zero-phase filtering now. And they're at least ~25x times faster than before! Removed Remove optional wavio dependency for audio loading 0.20.0 - 2021-11-18 Added Implement OneOf and SomeOf for applying one of or some of many transforms. Transforms are randomly chosen every call. Inspired by augly. Thanks to Cangonin and iver56. Add a new argument apply_to_children (bool) in randomize_parameters , freeze_parameters and unfreeze_parameters in Compose and SpecCompose . Changed Insert three new parameters in AddBackgroundNoise : noise_rms (defaults to \"relative\", which is the old behavior), min_absolute_rms_in_db and max_absolute_rms_in_db . This may be a breaking change if you used AddBackgroundNoise with positional arguments in earlier versions of audiomentations! Please use keyword arguments to be on the safe side - it should be backwards compatible then. Fixed Remove global pydub import which was accidentally introduced in v0.18.0. pydub is considered an optional dependency and is imported only on demand now. 0.19.0 - 2021-10-18 Added Implement TanhDistortion . Thanks to atamazian and iver56. Add a noise_rms parameter to AddShortNoises . It defaults to relative , which is the old behavior. absolute allows for adding loud noises to parts that are relatively silent in the input. 0.18.0 - 2021-08-05 Added Implement BandPassFilter , HighPassFilter , LowPassFilter and Reverse . Thanks to atamazian. 0.17.0 - 2021-06-25 Added Add a fade option in Shift for eliminating unwanted clicks Add support for 32-bit int wav loading with scipy>=1.6 Add support for float64 wav files. However, the use of this format is discouraged, since float32 is more than enough for audio in most cases. Implement Clip . Thanks to atamazian. Add some parameter sanity checks in AddGaussianNoise Officially support librosa 0.8.1 Changed Rename AddImpulseResponse to ApplyImpulseResponse . The former will still work for now, but give a warning. When looking for audio files in AddImpulseResponse , AddBackgroundNoise and AddShortNoises , follow symlinks by default. When using the new parameters min_snr_in_db and max_snr_in_db in AddGaussianSNR , SNRs will be picked uniformly in the decibel scale instead of in the linear amplitude ratio scale. The new behavior aligns more with human hearing, which is not linear. Fixed Avoid division by zero in AddImpulseResponse when input is digital silence (all zeros) Fix inverse SNR characteristics in AddGaussianSNR . It will continue working as before unless you switch to the new parameters min_snr_in_db and max_snr_in_db . If you use the old parameters, you'll get a warning. 0.16.0 - 2021-02-11 Added Implement SpecCompose for applying a pipeline of spectrogram transforms. Thanks to omerferhatt. Fixed Fix a bug in SpecChannelShuffle where it did not support more than 3 audio channels. Thanks to omerferhatt. Limit scipy version range to >=1.0,<1.6 to avoid issues with loading 24-bit wav files. Support for scipy>=1.6 will be added later. 0.15.0 - 2020-12-10 Added Add an option leave_length_unchanged to AddImpulseResponse Fixed Fix picklability of instances of AddImpulseResponse , AddBackgroundNoise and AddShortNoises 0.14.0 - 2020-12-06 Added Implement LoudnessNormalization Implement randomize_parameters in Compose . Thanks to SolomidHero. Add multichannel support to AddGaussianNoise , AddGaussianSNR , ClippingDistortion , FrequencyMask , PitchShift , Shift , TimeMask and TimeStretch 0.13.0 - 2020-11-10 Added Lay the foundation for spectrogram transforms. Implement SpecChannelShuffle and SpecFrequencyMask . Configurable LRU cache for transforms that use external sound files. Thanks to alumae. Officially add multichannel support to Normalize Changed Show a warning if a waveform had to be resampled after loading it. This is because resampling is slow. Ideally, files on disk should already have the desired sample rate. Fixed Correctly find audio files with upper case filename extensions. Fix a bug where AddBackgroundNoise crashed when trying to add digital silence to an input. Thanks to juheeuu. 0.12.1 - 2020-09-28 Changed Speed up AddBackgroundNoise , AddShortNoises and AddImpulseResponse by loading wav files with scipy or wavio instead of librosa. 0.12.0 - 2020-09-23 Added Implement Mp3Compression Officially support multichannel audio in Gain and PolarityInversion Add m4a and opus to the list of recognized audio filename extensions Changed Expand range of supported librosa versions Removed Python <= 3.5 is no longer officially supported, since Python 3.5 has reached end-of-life Breaking change: Internal util functions are no longer exposed directly. If you were doing e.g. from audiomentations import calculate_rms , now you have to do from audiomentations.core.utils import calculate_rms 0.11.0 - 2020-08-27 Added Implement Gain and PolarityInversion . Thanks to Spijkervet for the inspiration. 0.10.1 - 2020-07-27 Changed Improve the performance of AddBackgroundNoise and AddShortNoises by optimizing the implementation of calculate_rms . Fixed Improve compatibility of output files written by the demo script. Thanks to xwJohn. Fix division by zero bug in Normalize . Thanks to ZFTurbo. 0.10.0 - 2020-05-05 Added AddImpulseResponse , AddBackgroundNoise and AddShortNoises now support aiff files in addition to flac, mp3, ogg and wav Changed Breaking change: AddImpulseResponse , AddBackgroundNoise and AddShortNoises now include subfolders when searching for files. This is useful when your sound files are organized in subfolders. Fixed Fix filter instability bug in FrequencyMask . Thanks to kvilouras. 0.9.0 - 2020-02-20 Added Remember randomized/chosen effect parameters. This allows for freezing the parameters and applying the same effect to multiple sounds. Use transform.freeze_parameters() and transform.unfreeze_parameters() for this. Implement transform.serialize_parameters(). Useful for when you want to store metadata on how a sound was perturbed. Add a rollover parameter to Shift . This allows for introducing silence instead of a wrapped part of the sound. Add support for flac in AddImpulseResponse Implement AddBackgroundNoise transform. Useful for when you want to add background noise to all of your sound. You need to give it a folder of background noises to choose from. Implement AddShortNoises . Useful for when you want to add (bursts of) short noise sounds to your input audio. Changed Disregard non-audio files when looking for impulse response files Switch to a faster convolve implementation. This makes AddImpulseResponse significantly faster. Expand supported range of librosa versions Fixed Fix a bug in ClippingDistortion where the min_percentile_threshold was not respected as expected. Improve handling of empty input 0.8.0 - 2020-01-28 Added Add shuffle parameter in Composer Add Resample transformation Add ClippingDistortion transformation Add fade parameter to TimeMask Thanks to askskro 0.7.0 - 2020-01-14 Added AddGaussianSNR AddImpulseResponse FrequencyMask TimeMask Trim Thanks to karpnv 0.6.0 - 2019-05-27 Added Implement peak normalization 0.5.0 - 2019-02-23 Added Implement Shift transform Changed Ensure p is within bounds 0.4.0 - 2019-02-19 Added Implement PitchShift transform Fixed Fix output dtype of AddGaussianNoise 0.3.0 - 2019-02-19 Added Implement leave_length_unchanged in TimeStretch 0.2.0 - 2019-02-18 Added Add TimeStretch transform Parametrize AddGaussianNoise 0.1.0 - 2019-02-15 Added Initial release. Includes only one transform: AddGaussianNoise","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#0290-2023-03-15","text":"","title":"0.29.0 - 2023-03-15"},{"location":"changelog/#added","text":"Add apply_to parameter that can be set to \"only_too_loud_sounds\" in Normalize","title":"Added"},{"location":"changelog/#changed","text":"Change default value of noise_rms from \"relative\" to \"relative_to_whole_input\" in AddShortNoises Change default values of min_snr_in_db (from 0.0 to -6.0 ), max_snr_in_db (from 24.0 to 18.0 ), min_time_between_sounds (from 4.0 to 2.0 ) and max_time_between_sounds (from 16.0 to 8.0 ) in AddShortNoises","title":"Changed"},{"location":"changelog/#fixed","text":"Fix a bug where Limiter raised an exception when it got digital silence as input","title":"Fixed"},{"location":"changelog/#0280-2023-01-12","text":"","title":"0.28.0 - 2023-01-12"},{"location":"changelog/#added_1","text":"Add/improve type hints Add/improve documentation","title":"Added"},{"location":"changelog/#fixed_1","text":"Fix a bug in RoomSimulator where the value of max_order was not respected","title":"Fixed"},{"location":"changelog/#removed","text":"Remove FrequencyMask that had been deprecated since version 0.22.0. BandStopFilter is a good alternative.","title":"Removed"},{"location":"changelog/#0270-2022-09-13","text":"","title":"0.27.0 - 2022-09-13"},{"location":"changelog/#changed_1","text":"Speed up Limiter by ~8x Fix/improve some docstrings and type hints Change default values in Trim and ApplyImpulseResponse according to the warnings that were added in v0.23.0 Emit a FutureWarning when noise_rms in AddShortNoises is not specified - the default value will change from \"relative\" to \"relative_to_whole_input\" in a future version.","title":"Changed"},{"location":"changelog/#0260-2022-08-19","text":"","title":"0.26.0 - 2022-08-19"},{"location":"changelog/#added_2","text":"Add new transform Lambda . Thanks to Thanatoz-1. Add new transform Limiter . Thanks to pzelasko.","title":"Added"},{"location":"changelog/#fixed_2","text":"Fix incorrect type hints in RoomSimulator Make Shift robust to different sample rate inputs when parameters are frozen","title":"Fixed"},{"location":"changelog/#0251-2022-06-15","text":"","title":"0.25.1 - 2022-06-15"},{"location":"changelog/#fixed_3","text":"Fix a bug where RoomSimulator would treat an x value as if it was y, and vice versa","title":"Fixed"},{"location":"changelog/#0250-2022-05-30","text":"","title":"0.25.0 - 2022-05-30"},{"location":"changelog/#added_3","text":"Add AirAbsorption transform Add mp4 to the list of recognized audio filename extensions","title":"Added"},{"location":"changelog/#changed_2","text":"Guard against invalid params in TimeMask Emit FutureWarning instead of UserWarning in Trim and ApplyImpulseResponse Allow specifying a file path, a folder path, a list of files or a list of folders to ApplyImpulseResponse , AddBackgroundNoise and AddShortNoises . Previously only a path to a folder was allowed.","title":"Changed"},{"location":"changelog/#fixed_4","text":"Fix a bug with noise_transform in AddBackgroundNoise where some SNR calculations were done before the noise_transform was applied. This has sometimes led to incorrect SNR in the output. This changes the behavior of AddBackgroundNoise (when noise_transform is used).","title":"Fixed"},{"location":"changelog/#removed_1","text":"Remove support for Python 3.6, as it is past its end of life already. RIP.","title":"Removed"},{"location":"changelog/#0240-2022-03-18","text":"","title":"0.24.0 - 2022-03-18"},{"location":"changelog/#added_4","text":"Add SevenBandParametricEQ transform Add optional noise_transform in AddShortNoises Add .aac and .aif to the list of recognized audio filename endings","title":"Added"},{"location":"changelog/#changed_3","text":"Show warning if top_db and/or p in Trim are not specified because their default values will change in a future version","title":"Changed"},{"location":"changelog/#fixed_5","text":"Fix filter instability bug related to center freq above nyquist freq in LowShelfFilter and HighShelfFilter","title":"Fixed"},{"location":"changelog/#0230-2022-03-07","text":"","title":"0.23.0 - 2022-03-07"},{"location":"changelog/#added_5","text":"Add Padding transform Add RoomSimulator transform for simulating shoebox rooms using pyroomacoustics Add parameter signal_gain_in_db_during_noise in AddShortNoises","title":"Added"},{"location":"changelog/#changed_4","text":"Not specifying a value for leave_length_unchanged in AddImpulseResponse now emits a warning, as the default value will change from False to True in a future version.","title":"Changed"},{"location":"changelog/#removed_2","text":"Remove the deprecated AddImpulseResponse alias. Use ApplyImpulseResponse instead. Remove support for the legacy parameters min_SNR and max_SNR in AddGaussianSNR Remove useless default path value in AddBackgroundNoise , AddShortNoises and ApplyImpulseResponse","title":"Removed"},{"location":"changelog/#0220-2022-02-18","text":"","title":"0.22.0 - 2022-02-18"},{"location":"changelog/#added_6","text":"Implement GainTransition Add support for librosa 0.9 Add support for stereo audio in Mp3Compression , Resample and Trim Add \"relative_to_whole_input\" option for noise_rms parameter in AddShortNoises Add optional noise_transform in AddBackgroundNoise","title":"Added"},{"location":"changelog/#changed_5","text":"Improve speed of PitchShift by 6-18% when the input audio is stereo","title":"Changed"},{"location":"changelog/#deprecated","text":"Deprecate FrequencyMask in favor of BandStopFilter","title":"Deprecated"},{"location":"changelog/#removed_3","text":"Remove support for librosa<=0.7.2","title":"Removed"},{"location":"changelog/#0210-2022-02-10","text":"","title":"0.21.0 - 2022-02-10"},{"location":"changelog/#added_7","text":"Add support for multichannel audio in ApplyImpulseResponse , BandPassFilter , HighPassFilter and LowPassFilter Add BandStopFilter (similar to FrequencyMask, but with overhauled defaults and parameter randomization behavior), PeakingFilter , LowShelfFilter and HighShelfFilter Add parameter add_all_noises_with_same_level in AddShortNoises","title":"Added"},{"location":"changelog/#changed_6","text":"Change BandPassFilter , LowPassFilter , HighPassFilter , to use scipy's butterworth filters instead of pydub. Now they have parametrized roll-off. Filters are now steeper than before by default - set min_rolloff=6, max_rolloff=6 to get the old behavior. They also support zero-phase filtering now. And they're at least ~25x times faster than before!","title":"Changed"},{"location":"changelog/#removed_4","text":"Remove optional wavio dependency for audio loading","title":"Removed"},{"location":"changelog/#0200-2021-11-18","text":"","title":"0.20.0 - 2021-11-18"},{"location":"changelog/#added_8","text":"Implement OneOf and SomeOf for applying one of or some of many transforms. Transforms are randomly chosen every call. Inspired by augly. Thanks to Cangonin and iver56. Add a new argument apply_to_children (bool) in randomize_parameters , freeze_parameters and unfreeze_parameters in Compose and SpecCompose .","title":"Added"},{"location":"changelog/#changed_7","text":"Insert three new parameters in AddBackgroundNoise : noise_rms (defaults to \"relative\", which is the old behavior), min_absolute_rms_in_db and max_absolute_rms_in_db . This may be a breaking change if you used AddBackgroundNoise with positional arguments in earlier versions of audiomentations! Please use keyword arguments to be on the safe side - it should be backwards compatible then.","title":"Changed"},{"location":"changelog/#fixed_6","text":"Remove global pydub import which was accidentally introduced in v0.18.0. pydub is considered an optional dependency and is imported only on demand now.","title":"Fixed"},{"location":"changelog/#0190-2021-10-18","text":"","title":"0.19.0 - 2021-10-18"},{"location":"changelog/#added_9","text":"Implement TanhDistortion . Thanks to atamazian and iver56. Add a noise_rms parameter to AddShortNoises . It defaults to relative , which is the old behavior. absolute allows for adding loud noises to parts that are relatively silent in the input.","title":"Added"},{"location":"changelog/#0180-2021-08-05","text":"","title":"0.18.0 - 2021-08-05"},{"location":"changelog/#added_10","text":"Implement BandPassFilter , HighPassFilter , LowPassFilter and Reverse . Thanks to atamazian.","title":"Added"},{"location":"changelog/#0170-2021-06-25","text":"","title":"0.17.0 - 2021-06-25"},{"location":"changelog/#added_11","text":"Add a fade option in Shift for eliminating unwanted clicks Add support for 32-bit int wav loading with scipy>=1.6 Add support for float64 wav files. However, the use of this format is discouraged, since float32 is more than enough for audio in most cases. Implement Clip . Thanks to atamazian. Add some parameter sanity checks in AddGaussianNoise Officially support librosa 0.8.1","title":"Added"},{"location":"changelog/#changed_8","text":"Rename AddImpulseResponse to ApplyImpulseResponse . The former will still work for now, but give a warning. When looking for audio files in AddImpulseResponse , AddBackgroundNoise and AddShortNoises , follow symlinks by default. When using the new parameters min_snr_in_db and max_snr_in_db in AddGaussianSNR , SNRs will be picked uniformly in the decibel scale instead of in the linear amplitude ratio scale. The new behavior aligns more with human hearing, which is not linear.","title":"Changed"},{"location":"changelog/#fixed_7","text":"Avoid division by zero in AddImpulseResponse when input is digital silence (all zeros) Fix inverse SNR characteristics in AddGaussianSNR . It will continue working as before unless you switch to the new parameters min_snr_in_db and max_snr_in_db . If you use the old parameters, you'll get a warning.","title":"Fixed"},{"location":"changelog/#0160-2021-02-11","text":"","title":"0.16.0 - 2021-02-11"},{"location":"changelog/#added_12","text":"Implement SpecCompose for applying a pipeline of spectrogram transforms. Thanks to omerferhatt.","title":"Added"},{"location":"changelog/#fixed_8","text":"Fix a bug in SpecChannelShuffle where it did not support more than 3 audio channels. Thanks to omerferhatt. Limit scipy version range to >=1.0,<1.6 to avoid issues with loading 24-bit wav files. Support for scipy>=1.6 will be added later.","title":"Fixed"},{"location":"changelog/#0150-2020-12-10","text":"","title":"0.15.0 - 2020-12-10"},{"location":"changelog/#added_13","text":"Add an option leave_length_unchanged to AddImpulseResponse","title":"Added"},{"location":"changelog/#fixed_9","text":"Fix picklability of instances of AddImpulseResponse , AddBackgroundNoise and AddShortNoises","title":"Fixed"},{"location":"changelog/#0140-2020-12-06","text":"","title":"0.14.0 - 2020-12-06"},{"location":"changelog/#added_14","text":"Implement LoudnessNormalization Implement randomize_parameters in Compose . Thanks to SolomidHero. Add multichannel support to AddGaussianNoise , AddGaussianSNR , ClippingDistortion , FrequencyMask , PitchShift , Shift , TimeMask and TimeStretch","title":"Added"},{"location":"changelog/#0130-2020-11-10","text":"","title":"0.13.0 - 2020-11-10"},{"location":"changelog/#added_15","text":"Lay the foundation for spectrogram transforms. Implement SpecChannelShuffle and SpecFrequencyMask . Configurable LRU cache for transforms that use external sound files. Thanks to alumae. Officially add multichannel support to Normalize","title":"Added"},{"location":"changelog/#changed_9","text":"Show a warning if a waveform had to be resampled after loading it. This is because resampling is slow. Ideally, files on disk should already have the desired sample rate.","title":"Changed"},{"location":"changelog/#fixed_10","text":"Correctly find audio files with upper case filename extensions. Fix a bug where AddBackgroundNoise crashed when trying to add digital silence to an input. Thanks to juheeuu.","title":"Fixed"},{"location":"changelog/#0121-2020-09-28","text":"","title":"0.12.1 - 2020-09-28"},{"location":"changelog/#changed_10","text":"Speed up AddBackgroundNoise , AddShortNoises and AddImpulseResponse by loading wav files with scipy or wavio instead of librosa.","title":"Changed"},{"location":"changelog/#0120-2020-09-23","text":"","title":"0.12.0 - 2020-09-23"},{"location":"changelog/#added_16","text":"Implement Mp3Compression Officially support multichannel audio in Gain and PolarityInversion Add m4a and opus to the list of recognized audio filename extensions","title":"Added"},{"location":"changelog/#changed_11","text":"Expand range of supported librosa versions","title":"Changed"},{"location":"changelog/#removed_5","text":"Python <= 3.5 is no longer officially supported, since Python 3.5 has reached end-of-life Breaking change: Internal util functions are no longer exposed directly. If you were doing e.g. from audiomentations import calculate_rms , now you have to do from audiomentations.core.utils import calculate_rms","title":"Removed"},{"location":"changelog/#0110-2020-08-27","text":"","title":"0.11.0 - 2020-08-27"},{"location":"changelog/#added_17","text":"Implement Gain and PolarityInversion . Thanks to Spijkervet for the inspiration.","title":"Added"},{"location":"changelog/#0101-2020-07-27","text":"","title":"0.10.1 - 2020-07-27"},{"location":"changelog/#changed_12","text":"Improve the performance of AddBackgroundNoise and AddShortNoises by optimizing the implementation of calculate_rms .","title":"Changed"},{"location":"changelog/#fixed_11","text":"Improve compatibility of output files written by the demo script. Thanks to xwJohn. Fix division by zero bug in Normalize . Thanks to ZFTurbo.","title":"Fixed"},{"location":"changelog/#0100-2020-05-05","text":"","title":"0.10.0 - 2020-05-05"},{"location":"changelog/#added_18","text":"AddImpulseResponse , AddBackgroundNoise and AddShortNoises now support aiff files in addition to flac, mp3, ogg and wav","title":"Added"},{"location":"changelog/#changed_13","text":"Breaking change: AddImpulseResponse , AddBackgroundNoise and AddShortNoises now include subfolders when searching for files. This is useful when your sound files are organized in subfolders.","title":"Changed"},{"location":"changelog/#fixed_12","text":"Fix filter instability bug in FrequencyMask . Thanks to kvilouras.","title":"Fixed"},{"location":"changelog/#090-2020-02-20","text":"","title":"0.9.0 - 2020-02-20"},{"location":"changelog/#added_19","text":"Remember randomized/chosen effect parameters. This allows for freezing the parameters and applying the same effect to multiple sounds. Use transform.freeze_parameters() and transform.unfreeze_parameters() for this. Implement transform.serialize_parameters(). Useful for when you want to store metadata on how a sound was perturbed. Add a rollover parameter to Shift . This allows for introducing silence instead of a wrapped part of the sound. Add support for flac in AddImpulseResponse Implement AddBackgroundNoise transform. Useful for when you want to add background noise to all of your sound. You need to give it a folder of background noises to choose from. Implement AddShortNoises . Useful for when you want to add (bursts of) short noise sounds to your input audio.","title":"Added"},{"location":"changelog/#changed_14","text":"Disregard non-audio files when looking for impulse response files Switch to a faster convolve implementation. This makes AddImpulseResponse significantly faster. Expand supported range of librosa versions","title":"Changed"},{"location":"changelog/#fixed_13","text":"Fix a bug in ClippingDistortion where the min_percentile_threshold was not respected as expected. Improve handling of empty input","title":"Fixed"},{"location":"changelog/#080-2020-01-28","text":"","title":"0.8.0 - 2020-01-28"},{"location":"changelog/#added_20","text":"Add shuffle parameter in Composer Add Resample transformation Add ClippingDistortion transformation Add fade parameter to TimeMask Thanks to askskro","title":"Added"},{"location":"changelog/#070-2020-01-14","text":"","title":"0.7.0 - 2020-01-14"},{"location":"changelog/#added_21","text":"AddGaussianSNR AddImpulseResponse FrequencyMask TimeMask Trim Thanks to karpnv","title":"Added"},{"location":"changelog/#060-2019-05-27","text":"","title":"0.6.0 - 2019-05-27"},{"location":"changelog/#added_22","text":"Implement peak normalization","title":"Added"},{"location":"changelog/#050-2019-02-23","text":"","title":"0.5.0 - 2019-02-23"},{"location":"changelog/#added_23","text":"Implement Shift transform","title":"Added"},{"location":"changelog/#changed_15","text":"Ensure p is within bounds","title":"Changed"},{"location":"changelog/#040-2019-02-19","text":"","title":"0.4.0 - 2019-02-19"},{"location":"changelog/#added_24","text":"Implement PitchShift transform","title":"Added"},{"location":"changelog/#fixed_14","text":"Fix output dtype of AddGaussianNoise","title":"Fixed"},{"location":"changelog/#030-2019-02-19","text":"","title":"0.3.0 - 2019-02-19"},{"location":"changelog/#added_25","text":"Implement leave_length_unchanged in TimeStretch","title":"Added"},{"location":"changelog/#020-2019-02-18","text":"","title":"0.2.0 - 2019-02-18"},{"location":"changelog/#added_26","text":"Add TimeStretch transform Parametrize AddGaussianNoise","title":"Added"},{"location":"changelog/#010-2019-02-15","text":"","title":"0.1.0 - 2019-02-15"},{"location":"changelog/#added_27","text":"Initial release. Includes only one transform: AddGaussianNoise","title":"Added"},{"location":"spectrogram_transforms/","text":"audiomentations is in a very early (read: not very useful yet) stage when it comes to spectrogram transforms. Consider applying waveform transforms before converting your waveforms to spectrograms, or check out alternative libraries SpecChannelShuffle Added in v0.13.0 Shuffle the channels of a multichannel spectrogram. This can help combat positional bias. SpecFrequencyMask Added in v0.13.0 Mask a set of frequencies in a spectrogram, \u00e0 la Google AI SpecAugment. This type of data augmentation has proved to make speech recognition models more robust. The masked frequencies can be replaced with either the mean of the original values or a given constant (e.g. zero).","title":"Spectrogram transforms"},{"location":"spectrogram_transforms/#specchannelshuffle","text":"Added in v0.13.0 Shuffle the channels of a multichannel spectrogram. This can help combat positional bias.","title":"SpecChannelShuffle"},{"location":"spectrogram_transforms/#specfrequencymask","text":"Added in v0.13.0 Mask a set of frequencies in a spectrogram, \u00e0 la Google AI SpecAugment. This type of data augmentation has proved to make speech recognition models more robust. The masked frequencies can be replaced with either the mean of the original values or a given constant (e.g. zero).","title":"SpecFrequencyMask"},{"location":"guides/cpu_vs_gpu/","text":"CPU vs. GPU: Which to use for online data augmentation when training audio ML models? When training an audio machine learning model that includes online data augmentation as part of the training pipeline, you can choose to run the transforms on CPU or GPU. While some libraries, such as torch-audiomentations, support GPU, audiomentations is CPU-only. So, which one is better? The answer is: it depends. Pros of using CPU-only libraries like audiomentations There are several advantages to using CPU-only data augmentation libraries like audiomentations: Easy to get started: Audiomentations is straightforward to install and use, which makes it a good choice for beginners or for those who want to quickly prototype an idea. No VRAM usage: These libraries don't use valuable VRAM, which you might want to allocate to your model with large batch sizes. Often fast enough to keep GPU(s) busy: Running augmentations on CPU on multiple threads in a data loader can be fast enough to keep your GPU(s) busy, which means that data loading doesn't become a bottleneck if the model's GPU utilization is already high. This can speed up model training. Larger selection of transforms: Some types of transforms, such as Mp3Compression, only have CPU implementations that can't run on GPU. This means that audiomentations provides a more extensive selection of transforms than torch-audiomentations. Independent of specific tensor processing libraries: Audiomentations is CPU-only, which means it is not tied to a specific tensor processing library like TensorFlow or PyTorch. Pros of running audio augmentation transforms on GPU(s) There are also advantages to running audio augmentation transforms on GPU, for example, with the help of torch-audiomentations : Faster processing: When your model is not big enough to utilize your GPU fully (in terms of processing capabilities and VRAM), running transforms on GPU can make sense, especially when the transforms are much faster on GPU than on CPU. An example of this is convolution, which can be used for applying room reverb or various filters. Can speed up training: If running the data loader becomes a bottleneck when running the transforms on CPU, running transforms on GPU(s) instead can speed up the training. In summary, whether to use CPU-only libraries like audiomentations or GPU-accelerated libraries like torch-audiomentations depends on the specific requirements of your model and the available hardware. If your model training pipeline doesn't utilize your GPU(s) fully, running transforms on GPU might be the best choice. However, if your model's GPU utilization is already very high, running the transforms on multiple CPU threads might be the best option. It boils down to checking where your bottleneck is.","title":"CPU vs. GPU"},{"location":"guides/cpu_vs_gpu/#cpu-vs-gpu-which-to-use-for-online-data-augmentation-when-training-audio-ml-models","text":"When training an audio machine learning model that includes online data augmentation as part of the training pipeline, you can choose to run the transforms on CPU or GPU. While some libraries, such as torch-audiomentations, support GPU, audiomentations is CPU-only. So, which one is better? The answer is: it depends.","title":"CPU vs. GPU: Which to use for online data augmentation when training audio ML models?"},{"location":"guides/cpu_vs_gpu/#pros-of-using-cpu-only-libraries-like-audiomentations","text":"There are several advantages to using CPU-only data augmentation libraries like audiomentations: Easy to get started: Audiomentations is straightforward to install and use, which makes it a good choice for beginners or for those who want to quickly prototype an idea. No VRAM usage: These libraries don't use valuable VRAM, which you might want to allocate to your model with large batch sizes. Often fast enough to keep GPU(s) busy: Running augmentations on CPU on multiple threads in a data loader can be fast enough to keep your GPU(s) busy, which means that data loading doesn't become a bottleneck if the model's GPU utilization is already high. This can speed up model training. Larger selection of transforms: Some types of transforms, such as Mp3Compression, only have CPU implementations that can't run on GPU. This means that audiomentations provides a more extensive selection of transforms than torch-audiomentations. Independent of specific tensor processing libraries: Audiomentations is CPU-only, which means it is not tied to a specific tensor processing library like TensorFlow or PyTorch.","title":"Pros of using CPU-only libraries like audiomentations"},{"location":"guides/cpu_vs_gpu/#pros-of-running-audio-augmentation-transforms-on-gpus","text":"There are also advantages to running audio augmentation transforms on GPU, for example, with the help of torch-audiomentations : Faster processing: When your model is not big enough to utilize your GPU fully (in terms of processing capabilities and VRAM), running transforms on GPU can make sense, especially when the transforms are much faster on GPU than on CPU. An example of this is convolution, which can be used for applying room reverb or various filters. Can speed up training: If running the data loader becomes a bottleneck when running the transforms on CPU, running transforms on GPU(s) instead can speed up the training. In summary, whether to use CPU-only libraries like audiomentations or GPU-accelerated libraries like torch-audiomentations depends on the specific requirements of your model and the available hardware. If your model training pipeline doesn't utilize your GPU(s) fully, running transforms on GPU might be the best choice. However, if your model's GPU utilization is already very high, running the transforms on multiple CPU threads might be the best option. It boils down to checking where your bottleneck is.","title":"Pros of running audio augmentation transforms on GPU(s)"},{"location":"guides/transform_parameters/","text":"Transform parameters How to obtain the chosen parameters after calling a transform You can access the parameters property of a transform. Code example: from audiomentations import Compose , AddGaussianNoise , TimeStretch , PitchShift , Shift import numpy as np augment = Compose ([ AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 0.5 ), TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , p = 0.5 ), PitchShift ( min_semitones =- 4 , max_semitones = 4 , p = 0.5 ), Shift ( min_fraction =- 0.5 , max_fraction = 0.5 , p = 0.5 ), ]) # Generate 2 seconds of dummy audio for the sake of example samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) # Augment/transform/perturb the audio data augmented_samples = augment ( samples = samples , sample_rate = 16000 ) for transform in augment . transforms : print ( f \" { transform . __class__ . __name__ } : { transform . parameters } \" ) When running the example code above, it may print something like this: AddGaussianNoise: {'should_apply': True, 'amplitude': 0.0027702725003923272} TimeStretch: {'should_apply': True, 'rate': 1.158377360016495} PitchShift: {'should_apply': False} Shift: {'should_apply': False} How to use apply a transform with the same parameters to multiple inputs This technique can be useful if you want to transform e.g. a target sound in the same way as an input sound. Code example: from audiomentations import Gain import numpy as np augment = Gain ( p = 1.0 ) samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) samples2 = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) augmented_samples = augment ( samples = samples , sample_rate = 16000 ) augment . freeze_parameters () print ( augment . parameters ) augmented_samples2 = augment ( samples = samples2 , sample_rate = 16000 ) print ( augment . parameters ) augment . unfreeze_parameters () When running the example code above, it may print something like this: {'should_apply': True, 'amplitude_ratio': 0.9688148624484364} {'should_apply': True, 'amplitude_ratio': 0.9688148624484364} In other words, this means that both sounds ( samples and samples2 ) were gained by the same amount","title":"Transform parameters"},{"location":"guides/transform_parameters/#transform-parameters","text":"","title":"Transform parameters"},{"location":"guides/transform_parameters/#how-to-obtain-the-chosen-parameters-after-calling-a-transform","text":"You can access the parameters property of a transform. Code example: from audiomentations import Compose , AddGaussianNoise , TimeStretch , PitchShift , Shift import numpy as np augment = Compose ([ AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 0.5 ), TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , p = 0.5 ), PitchShift ( min_semitones =- 4 , max_semitones = 4 , p = 0.5 ), Shift ( min_fraction =- 0.5 , max_fraction = 0.5 , p = 0.5 ), ]) # Generate 2 seconds of dummy audio for the sake of example samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) # Augment/transform/perturb the audio data augmented_samples = augment ( samples = samples , sample_rate = 16000 ) for transform in augment . transforms : print ( f \" { transform . __class__ . __name__ } : { transform . parameters } \" ) When running the example code above, it may print something like this: AddGaussianNoise: {'should_apply': True, 'amplitude': 0.0027702725003923272} TimeStretch: {'should_apply': True, 'rate': 1.158377360016495} PitchShift: {'should_apply': False} Shift: {'should_apply': False}","title":"How to obtain the chosen parameters after calling a transform"},{"location":"guides/transform_parameters/#how-to-use-apply-a-transform-with-the-same-parameters-to-multiple-inputs","text":"This technique can be useful if you want to transform e.g. a target sound in the same way as an input sound. Code example: from audiomentations import Gain import numpy as np augment = Gain ( p = 1.0 ) samples = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) samples2 = np . random . uniform ( low =- 0.2 , high = 0.2 , size = ( 32000 ,)) . astype ( np . float32 ) augmented_samples = augment ( samples = samples , sample_rate = 16000 ) augment . freeze_parameters () print ( augment . parameters ) augmented_samples2 = augment ( samples = samples2 , sample_rate = 16000 ) print ( augment . parameters ) augment . unfreeze_parameters () When running the example code above, it may print something like this: {'should_apply': True, 'amplitude_ratio': 0.9688148624484364} {'should_apply': True, 'amplitude_ratio': 0.9688148624484364} In other words, this means that both sounds ( samples and samples2 ) were gained by the same amount","title":"How to use apply a transform with the same parameters to multiple inputs"},{"location":"waveform_transforms/add_background_noise/","text":"AddBackgroundNoise Added in v0.9.0 Mix in another sound, e.g. a background noise. Useful if your original sound is clean and you want to simulate an environment where background noise is present. Can also be used for mixup when training classification/annotation models. A path to a file/folder with sound(s), or a list of file/folder paths, must be specified. These sounds should ideally be at least as long as the input sounds to be transformed. Otherwise, the background sound will be repeated, which may sound unnatural. Note that in the default case ( noise_rms=\"relative\" ) the gain of the added noise is relative to the amount of signal in the input. This implies that if the input is completely silent, no noise will be added. Optionally, the added noise sound can be transformed (with noise_transform ) before it gets mixed in. Here are some examples of datasets that can be downloaded and used as background noise: https://github.com/karolpiczak/ESC-50#download https://github.com/microsoft/DNS-Challenge/ Input-output example Here we add some music to a speech recording, targeting a signal-to-noise ratio (SNR) of 5 decibels (dB), which means that the speech ( signal ) is 5 dB louder than the music ( noise ). Input sound Transformed sound Usage examples Relative RMS Absolute RMS from audiomentations import AddBackgroundNoise , PolarityInversion transform = AddBackgroundNoise ( sounds_path = \"/path/to/folder_with_sound_files\" , min_snr_in_db = 3.0 , max_snr_in_db = 30.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AddBackgroundNoise , PolarityInversion transform = AddBackgroundNoise ( sounds_path = \"/path/to/folder_with_sound_files\" , noise_rms = \"absolute\" , min_absolute_rms_in_db =- 45.0 , max_absolute_rms_in_db =- 15.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) AddBackgroundNoise API sounds_path : Union[List[Path], List[str], Path, str] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be background noises. min_snr_in_db : float \u2022 unit: Decibel Default: 3.0 . Minimum signal-to-noise ratio in dB. Is only used if noise_rms is set to \"relative\" max_snr_in_db : float \u2022 unit: Decibel Default: 30.0 . Maximum signal-to-noise ratio in dB. Is only used if noise_rms is set to \"relative\" noise_rms : str \u2022 choices: \"absolute\" , \"relative\" Default: \"relative\" . Defines how the background noise will be added to the audio input. If the chosen option is \"relative\" , the root mean square (RMS) of the added noise will be proportional to the RMS of the input sound. If the chosen option is \"absolute\" , the background noise will have an RMS independent of the rms of the input audio file min_absolute_rms_in_db : float \u2022 unit: Decibel Default: -45.0 . Is only used if noise_rms is set to \"absolute\" . It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower the added sound will be. max_absolute_rms_in_db : float \u2022 unit: Decibel Default: -15.0 . Is only used if noise_rms is set to \"absolute\" . It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. noise_transform : Optional[Callable[[np.ndarray, int], np.ndarray]] Default: None . A callable waveform transform (or composition of transforms) that gets applied to the noise before it gets mixed in. The callable is expected to input audio waveform (numpy array) and sample rate (int). p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 2 . Maximum size of the LRU cache for storing noise files in memory","title":"AddBackgroundNoise"},{"location":"waveform_transforms/add_background_noise/#addbackgroundnoise","text":"Added in v0.9.0 Mix in another sound, e.g. a background noise. Useful if your original sound is clean and you want to simulate an environment where background noise is present. Can also be used for mixup when training classification/annotation models. A path to a file/folder with sound(s), or a list of file/folder paths, must be specified. These sounds should ideally be at least as long as the input sounds to be transformed. Otherwise, the background sound will be repeated, which may sound unnatural. Note that in the default case ( noise_rms=\"relative\" ) the gain of the added noise is relative to the amount of signal in the input. This implies that if the input is completely silent, no noise will be added. Optionally, the added noise sound can be transformed (with noise_transform ) before it gets mixed in. Here are some examples of datasets that can be downloaded and used as background noise: https://github.com/karolpiczak/ESC-50#download https://github.com/microsoft/DNS-Challenge/","title":"AddBackgroundNoise"},{"location":"waveform_transforms/add_background_noise/#input-output-example","text":"Here we add some music to a speech recording, targeting a signal-to-noise ratio (SNR) of 5 decibels (dB), which means that the speech ( signal ) is 5 dB louder than the music ( noise ). Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/add_background_noise/#usage-examples","text":"Relative RMS Absolute RMS from audiomentations import AddBackgroundNoise , PolarityInversion transform = AddBackgroundNoise ( sounds_path = \"/path/to/folder_with_sound_files\" , min_snr_in_db = 3.0 , max_snr_in_db = 30.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AddBackgroundNoise , PolarityInversion transform = AddBackgroundNoise ( sounds_path = \"/path/to/folder_with_sound_files\" , noise_rms = \"absolute\" , min_absolute_rms_in_db =- 45.0 , max_absolute_rms_in_db =- 15.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage examples"},{"location":"waveform_transforms/add_background_noise/#addbackgroundnoise-api","text":"sounds_path : Union[List[Path], List[str], Path, str] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be background noises. min_snr_in_db : float \u2022 unit: Decibel Default: 3.0 . Minimum signal-to-noise ratio in dB. Is only used if noise_rms is set to \"relative\" max_snr_in_db : float \u2022 unit: Decibel Default: 30.0 . Maximum signal-to-noise ratio in dB. Is only used if noise_rms is set to \"relative\" noise_rms : str \u2022 choices: \"absolute\" , \"relative\" Default: \"relative\" . Defines how the background noise will be added to the audio input. If the chosen option is \"relative\" , the root mean square (RMS) of the added noise will be proportional to the RMS of the input sound. If the chosen option is \"absolute\" , the background noise will have an RMS independent of the rms of the input audio file min_absolute_rms_in_db : float \u2022 unit: Decibel Default: -45.0 . Is only used if noise_rms is set to \"absolute\" . It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower the added sound will be. max_absolute_rms_in_db : float \u2022 unit: Decibel Default: -15.0 . Is only used if noise_rms is set to \"absolute\" . It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. noise_transform : Optional[Callable[[np.ndarray, int], np.ndarray]] Default: None . A callable waveform transform (or composition of transforms) that gets applied to the noise before it gets mixed in. The callable is expected to input audio waveform (numpy array) and sample rate (int). p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 2 . Maximum size of the LRU cache for storing noise files in memory","title":"AddBackgroundNoise API"},{"location":"waveform_transforms/add_gaussian_noise/","text":"AddGaussianNoise Added in v0.1.0 Add gaussian noise to the samples Input-output example Here we add some gaussian noise (with amplitude 0.01) to a speech recording. Input sound Transformed sound Usage example from audiomentations import AddGaussianNoise transform = AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) AddGaussianNoise API min_amplitude : float \u2022 unit: linear amplitude Default: 0.001 . Minimum noise amplification factor. max_amplitude : float \u2022 unit: linear amplitude Default: 0.015 . Maximum noise amplification factor. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AddGaussianNoise"},{"location":"waveform_transforms/add_gaussian_noise/#addgaussiannoise","text":"Added in v0.1.0 Add gaussian noise to the samples","title":"AddGaussianNoise"},{"location":"waveform_transforms/add_gaussian_noise/#input-output-example","text":"Here we add some gaussian noise (with amplitude 0.01) to a speech recording. Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/add_gaussian_noise/#usage-example","text":"from audiomentations import AddGaussianNoise transform = AddGaussianNoise ( min_amplitude = 0.001 , max_amplitude = 0.015 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/add_gaussian_noise/#addgaussiannoise-api","text":"min_amplitude : float \u2022 unit: linear amplitude Default: 0.001 . Minimum noise amplification factor. max_amplitude : float \u2022 unit: linear amplitude Default: 0.015 . Maximum noise amplification factor. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AddGaussianNoise API"},{"location":"waveform_transforms/add_gaussian_snr/","text":"AddGaussianSNR Added in v0.7.0 Add gaussian noise to the input. A random Signal to Noise Ratio (SNR) will be picked uniformly in the decibel scale. This aligns with human hearing, which is more logarithmic than linear. Usage example from audiomentations import AddGaussianSNR transform = AddGaussianSNR ( min_snr_in_db = 5.0 , max_snr_in_db = 40.0 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) AddGaussianSNR API min_snr_in_db : float \u2022 unit: Decibel Default: 5.0 . Minimum signal-to-noise ratio in dB. A lower number means more noise. max_snr_in_db : float \u2022 unit: decibel Default: 40.0 . Maximum signal-to-noise ratio in dB. A greater number means less noise. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AddGaussianSNR"},{"location":"waveform_transforms/add_gaussian_snr/#addgaussiansnr","text":"Added in v0.7.0 Add gaussian noise to the input. A random Signal to Noise Ratio (SNR) will be picked uniformly in the decibel scale. This aligns with human hearing, which is more logarithmic than linear.","title":"AddGaussianSNR"},{"location":"waveform_transforms/add_gaussian_snr/#usage-example","text":"from audiomentations import AddGaussianSNR transform = AddGaussianSNR ( min_snr_in_db = 5.0 , max_snr_in_db = 40.0 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/add_gaussian_snr/#addgaussiansnr-api","text":"min_snr_in_db : float \u2022 unit: Decibel Default: 5.0 . Minimum signal-to-noise ratio in dB. A lower number means more noise. max_snr_in_db : float \u2022 unit: decibel Default: 40.0 . Maximum signal-to-noise ratio in dB. A greater number means less noise. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AddGaussianSNR API"},{"location":"waveform_transforms/add_short_noises/","text":"AddShortNoises Added in v0.9.0 Mix in various (bursts of overlapping) sounds with random pauses between. Useful if your original sound is clean and you want to simulate an environment where short noises sometimes occur. A folder of (noise) sounds to be mixed in must be specified. Input-output example Here we add some short noise sounds to a voice recording. Input sound Transformed sound Usage examples Noise RMS relative to whole input Absolute RMS from audiomentations import AddShortNoises , PolarityInversion transform = AddShortNoises ( sounds_path = \"/path/to/folder_with_sound_files\" , min_snr_in_db = 3.0 , max_snr_in_db = 30.0 , noise_rms = \"relative_to_whole_input\" , min_time_between_sounds = 2.0 , max_time_between_sounds = 8.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AddShortNoises , PolarityInversion transform = AddShortNoises ( sounds_path = \"/path/to/folder_with_sound_files\" , min_absolute_noise_rms_db =- 50.0 , max_absolute_noise_rms_db =- 20.0 , noise_rms = \"absolute\" , min_time_between_sounds = 2.0 , max_time_between_sounds = 8.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) AddShortNoises API sounds_path : Union[List[Path], List[str], Path, str] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be (short) noises. min_snr_in_db : float \u2022 unit: Decibel Default: 0.0 (changed to -6.0 since v0.29.0). Minimum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if noise_rms is set to \"absolute\" . max_snr_in_db : float \u2022 unit: Decibel Default: 24.0 (changed to 18.0 since v0.29.0). Maximum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if noise_rms is set to \"absolute\" . min_time_between_sounds : float \u2022 unit: seconds Default: 4.0 (changed to 2.0 since v0.29.0). Minimum pause time (in seconds) between the added sounds/noises max_time_between_sounds : float \u2022 unit: seconds Default: 16.0 (changed to 8.0 since v0.29.0). Maximum pause time (in seconds) between the added sounds/noises noise_rms : str \u2022 choices: \"absolute\" , \"relative\" , \"relative_to_whole_input\" Default: \"relative\" (<=v0.27), but will be changed to \"relative_to_whole_input\" in a future version. This parameter defines how the noises will be added to the audio input. \"relative\" : the RMS value of the added noise will be proportional to the RMS value of the input sound calculated only for the region where the noise is added. \"absolute\" : the added noises will have an RMS independent of the RMS of the input audio file. \"relative_to_whole_input\" : the RMS of the added noises will be proportional to the RMS of the whole input sound. min_absolute_noise_rms_db : float \u2022 unit: Decibel Default: -50.0 . Is only used if noise_rms is set to \"absolute\" . It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower will the added sound be. max_absolute_noise_rms_db : float \u2022 unit: seconds Default: -20.0 . Is only used if noise_rms is set to \"absolute\" . It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. add_all_noises_with_same_level : bool Default: False . Whether to add all the short noises (within one audio snippet) with the same SNR. If noise_rms is set to \"absolute\" , the RMS is used instead of SNR. The target SNR (or RMS) will change every time the parameters of the transform are randomized. include_silence_in_noise_rms_estimation : bool Default: True . It chooses how the RMS of the noises to be added will be calculated. If this option is set to False, the silence in the noise files will be disregarded in the RMS calculation. It is useful for non-stationary noises where silent periods occur. burst_probability : float Default: 0.22 . For every noise that gets added, there is a probability of adding an extra burst noise that overlaps with the noise. This parameter controls that probability. min_pause_factor_during_burst and max_pause_factor_during_burst control the amount of overlap. min_pause_factor_during_burst : float Default: 0.1 . Min value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. max_pause_factor_during_burst : float Default: 1.1 . Max value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. min_fade_in_time : float \u2022 unit: seconds Default: 0.005 . Min noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. max_fade_in_time : float \u2022 unit: seconds Default: 0.08 . Max noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. min_fade_out_time : float \u2022 unit: seconds Default: 0.01 . Min sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. max_fade_out_time : float \u2022 unit: seconds Default: 0.1 . Max sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. signal_gain_in_db_during_noise : float \u2022 unit: Decibel Default: 0.0 . Gain applied to the signal during a short noise. When fading the signal to the custom gain, the same fade times are used as for the noise, so it's essentially cross-fading. The default value (0.0) means the signal will not be gained. If set to a very low value, e.g. -100.0, this feature could be used for completely replacing the signal with the noise. This could be relevant in some use cases, for example: replace the signal with another signal of a similar class (e.g. replace some speech with a cough) simulate an ECG off-lead condition (electrodes are temporarily disconnected) noise_transform : Optional[Callable[[np.ndarray, int], np.ndarray]] Default: None . A callable waveform transform (or composition of transforms) that gets applied to noises before they get mixed in. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 64 . Maximum size of the LRU cache for storing noise files in memory","title":"AddShortNoises"},{"location":"waveform_transforms/add_short_noises/#addshortnoises","text":"Added in v0.9.0 Mix in various (bursts of overlapping) sounds with random pauses between. Useful if your original sound is clean and you want to simulate an environment where short noises sometimes occur. A folder of (noise) sounds to be mixed in must be specified.","title":"AddShortNoises"},{"location":"waveform_transforms/add_short_noises/#input-output-example","text":"Here we add some short noise sounds to a voice recording. Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/add_short_noises/#usage-examples","text":"Noise RMS relative to whole input Absolute RMS from audiomentations import AddShortNoises , PolarityInversion transform = AddShortNoises ( sounds_path = \"/path/to/folder_with_sound_files\" , min_snr_in_db = 3.0 , max_snr_in_db = 30.0 , noise_rms = \"relative_to_whole_input\" , min_time_between_sounds = 2.0 , max_time_between_sounds = 8.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AddShortNoises , PolarityInversion transform = AddShortNoises ( sounds_path = \"/path/to/folder_with_sound_files\" , min_absolute_noise_rms_db =- 50.0 , max_absolute_noise_rms_db =- 20.0 , noise_rms = \"absolute\" , min_time_between_sounds = 2.0 , max_time_between_sounds = 8.0 , noise_transform = PolarityInversion (), p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage examples"},{"location":"waveform_transforms/add_short_noises/#addshortnoises-api","text":"sounds_path : Union[List[Path], List[str], Path, str] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be (short) noises. min_snr_in_db : float \u2022 unit: Decibel Default: 0.0 (changed to -6.0 since v0.29.0). Minimum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if noise_rms is set to \"absolute\" . max_snr_in_db : float \u2022 unit: Decibel Default: 24.0 (changed to 18.0 since v0.29.0). Maximum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if noise_rms is set to \"absolute\" . min_time_between_sounds : float \u2022 unit: seconds Default: 4.0 (changed to 2.0 since v0.29.0). Minimum pause time (in seconds) between the added sounds/noises max_time_between_sounds : float \u2022 unit: seconds Default: 16.0 (changed to 8.0 since v0.29.0). Maximum pause time (in seconds) between the added sounds/noises noise_rms : str \u2022 choices: \"absolute\" , \"relative\" , \"relative_to_whole_input\" Default: \"relative\" (<=v0.27), but will be changed to \"relative_to_whole_input\" in a future version. This parameter defines how the noises will be added to the audio input. \"relative\" : the RMS value of the added noise will be proportional to the RMS value of the input sound calculated only for the region where the noise is added. \"absolute\" : the added noises will have an RMS independent of the RMS of the input audio file. \"relative_to_whole_input\" : the RMS of the added noises will be proportional to the RMS of the whole input sound. min_absolute_noise_rms_db : float \u2022 unit: Decibel Default: -50.0 . Is only used if noise_rms is set to \"absolute\" . It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower will the added sound be. max_absolute_noise_rms_db : float \u2022 unit: seconds Default: -20.0 . Is only used if noise_rms is set to \"absolute\" . It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. add_all_noises_with_same_level : bool Default: False . Whether to add all the short noises (within one audio snippet) with the same SNR. If noise_rms is set to \"absolute\" , the RMS is used instead of SNR. The target SNR (or RMS) will change every time the parameters of the transform are randomized. include_silence_in_noise_rms_estimation : bool Default: True . It chooses how the RMS of the noises to be added will be calculated. If this option is set to False, the silence in the noise files will be disregarded in the RMS calculation. It is useful for non-stationary noises where silent periods occur. burst_probability : float Default: 0.22 . For every noise that gets added, there is a probability of adding an extra burst noise that overlaps with the noise. This parameter controls that probability. min_pause_factor_during_burst and max_pause_factor_during_burst control the amount of overlap. min_pause_factor_during_burst : float Default: 0.1 . Min value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. max_pause_factor_during_burst : float Default: 1.1 . Max value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. min_fade_in_time : float \u2022 unit: seconds Default: 0.005 . Min noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. max_fade_in_time : float \u2022 unit: seconds Default: 0.08 . Max noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. min_fade_out_time : float \u2022 unit: seconds Default: 0.01 . Min sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. max_fade_out_time : float \u2022 unit: seconds Default: 0.1 . Max sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. signal_gain_in_db_during_noise : float \u2022 unit: Decibel Default: 0.0 . Gain applied to the signal during a short noise. When fading the signal to the custom gain, the same fade times are used as for the noise, so it's essentially cross-fading. The default value (0.0) means the signal will not be gained. If set to a very low value, e.g. -100.0, this feature could be used for completely replacing the signal with the noise. This could be relevant in some use cases, for example: replace the signal with another signal of a similar class (e.g. replace some speech with a cough) simulate an ECG off-lead condition (electrodes are temporarily disconnected) noise_transform : Optional[Callable[[np.ndarray, int], np.ndarray]] Default: None . A callable waveform transform (or composition of transforms) that gets applied to noises before they get mixed in. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 64 . Maximum size of the LRU cache for storing noise files in memory","title":"AddShortNoises API"},{"location":"waveform_transforms/adjust_duration/","text":"AdjustDuration Added in v0.30.0 Trim or pad the audio to the specified length/duration in samples or seconds. If the input sound is longer than the target duration, pick a random offset and crop the sound to the target duration. If the input sound is shorter than the target duration, pad the sound so the duration matches the target duration. This transform can be useful if you need audio with constant length, e.g. as input to a machine learning model. The reason for varying audio clip lengths can be e.g. the nature of the audio dataset (different audio clips have different lengths) data augmentation transforms that change the lengths (e.g. time stretching or convolving with impulse responses without cutting the tail) Input-output example Here we input an audio clip and remove a part of the start and the end, so the length of the result matches the specified target length. Input sound Transformed sound Usage examples Target length in samples Target duration in seconds from audiomentations import AdjustDuration transform = AdjustDuration ( duration_samples = 60000 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AdjustDuration transform = AdjustDuration ( duration_seconds = 3.75 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) AdjustDuration API duration_samples : int \u2022 range: [0, \u221e) Target duration in number of samples. duration_seconds : float \u2022 range: [0.0, \u221e) Target duration in seconds. padding_mode : str \u2022 choices: \"silence\" , \"wrap\" , \"reflect\" Default: \"silence\" . Padding mode. Only used when audio input is shorter than the target duration. padding_position : str \u2022 choices: \"start\" , \"end\" Default: \"end\" . The position of the inserted/added padding. Only used when audio input is shorter than the target duration. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AdjustDuration"},{"location":"waveform_transforms/adjust_duration/#adjustduration","text":"Added in v0.30.0 Trim or pad the audio to the specified length/duration in samples or seconds. If the input sound is longer than the target duration, pick a random offset and crop the sound to the target duration. If the input sound is shorter than the target duration, pad the sound so the duration matches the target duration. This transform can be useful if you need audio with constant length, e.g. as input to a machine learning model. The reason for varying audio clip lengths can be e.g. the nature of the audio dataset (different audio clips have different lengths) data augmentation transforms that change the lengths (e.g. time stretching or convolving with impulse responses without cutting the tail)","title":"AdjustDuration"},{"location":"waveform_transforms/adjust_duration/#input-output-example","text":"Here we input an audio clip and remove a part of the start and the end, so the length of the result matches the specified target length. Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/adjust_duration/#usage-examples","text":"Target length in samples Target duration in seconds from audiomentations import AdjustDuration transform = AdjustDuration ( duration_samples = 60000 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) from audiomentations import AdjustDuration transform = AdjustDuration ( duration_seconds = 3.75 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage examples"},{"location":"waveform_transforms/adjust_duration/#adjustduration-api","text":"duration_samples : int \u2022 range: [0, \u221e) Target duration in number of samples. duration_seconds : float \u2022 range: [0.0, \u221e) Target duration in seconds. padding_mode : str \u2022 choices: \"silence\" , \"wrap\" , \"reflect\" Default: \"silence\" . Padding mode. Only used when audio input is shorter than the target duration. padding_position : str \u2022 choices: \"start\" , \"end\" Default: \"end\" . The position of the inserted/added padding. Only used when audio input is shorter than the target duration. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AdjustDuration API"},{"location":"waveform_transforms/air_absorption/","text":"AirAbsorption Added in v0.25.0 A lowpass-like filterbank with variable octave attenuation that simulates attenuation of high frequencies due to air absorption. This transform is parametrized by temperature, humidity, and the distance between audio source and microphone. This is not a scientifically accurate transform but basically applies a uniform filterbank with attenuations given by: att = exp(- distance * absorption_coefficient) where distance is the microphone-source assumed distance in meters and absorption_coefficient is adapted from a lookup table by pyroomacoustics . It can also be seen as a lowpass filter with variable octave attenuation. Note: This only \"simulates\" the dampening of high frequencies, and does not attenuate according to the distance law. Gain augmentation needs to be done separately. AirAbsorption API min_temperature : float \u2022 unit: Celsius \u2022 choices: [10.0, 20.0] Default: 10.0 . Minimum temperature in Celsius (can take a value of either 10.0 or 20.0) max_temperature : float \u2022 unit: Celsius \u2022 choices: [10.0, 20.0] Default: 20.0 . Maximum temperature in Celsius (can take a value of either 10.0 or 20.0) min_humidity : float \u2022 unit: percent \u2022 range: [30.0, 90.0] Default: 30.0 . Minimum humidity in percent (between 30.0 and 90.0) max_humidity : float \u2022 unit: percent \u2022 range: [30.0, 90.0] Default: 90.0 . Maximum humidity in percent (between 30.0 and 90.0) min_distance : float \u2022 unit: meters Default: 10.0 . Minimum microphone-source distance in meters. max_distance : float \u2022 unit: meters Default: 100.0 . Maximum microphone-source distance in meters. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AirAbsorption"},{"location":"waveform_transforms/air_absorption/#airabsorption","text":"Added in v0.25.0 A lowpass-like filterbank with variable octave attenuation that simulates attenuation of high frequencies due to air absorption. This transform is parametrized by temperature, humidity, and the distance between audio source and microphone. This is not a scientifically accurate transform but basically applies a uniform filterbank with attenuations given by: att = exp(- distance * absorption_coefficient) where distance is the microphone-source assumed distance in meters and absorption_coefficient is adapted from a lookup table by pyroomacoustics . It can also be seen as a lowpass filter with variable octave attenuation. Note: This only \"simulates\" the dampening of high frequencies, and does not attenuate according to the distance law. Gain augmentation needs to be done separately.","title":"AirAbsorption"},{"location":"waveform_transforms/air_absorption/#airabsorption-api","text":"min_temperature : float \u2022 unit: Celsius \u2022 choices: [10.0, 20.0] Default: 10.0 . Minimum temperature in Celsius (can take a value of either 10.0 or 20.0) max_temperature : float \u2022 unit: Celsius \u2022 choices: [10.0, 20.0] Default: 20.0 . Maximum temperature in Celsius (can take a value of either 10.0 or 20.0) min_humidity : float \u2022 unit: percent \u2022 range: [30.0, 90.0] Default: 30.0 . Minimum humidity in percent (between 30.0 and 90.0) max_humidity : float \u2022 unit: percent \u2022 range: [30.0, 90.0] Default: 90.0 . Maximum humidity in percent (between 30.0 and 90.0) min_distance : float \u2022 unit: meters Default: 10.0 . Minimum microphone-source distance in meters. max_distance : float \u2022 unit: meters Default: 100.0 . Maximum microphone-source distance in meters. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"AirAbsorption API"},{"location":"waveform_transforms/apply_impulse_response/","text":"ApplyImpulseResponse Added in v0.7.0 Convolve the audio with a randomly selected impulse response. Impulse responses can be created using e.g. http://tulrich.com/recording/ir_capture/ Some datasets of impulse responses are publicly available: - EchoThief containing 115 impulse responses acquired in a wide range of locations. - The MIT McDermott dataset containing 271 impulse responses acquired in everyday places. Impulse responses are represented as audio (ideally wav) files in the given ir_path . ApplyImpulseResponse API ir_path : Union[List[Path], List[str], str, Path] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be impulse responses. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 128 . Maximum size of the LRU cache for storing impulse response files in memory. leave_length_unchanged : bool Default: True . When set to True , the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input.","title":"ApplyImpulseResponse"},{"location":"waveform_transforms/apply_impulse_response/#applyimpulseresponse","text":"Added in v0.7.0 Convolve the audio with a randomly selected impulse response. Impulse responses can be created using e.g. http://tulrich.com/recording/ir_capture/ Some datasets of impulse responses are publicly available: - EchoThief containing 115 impulse responses acquired in a wide range of locations. - The MIT McDermott dataset containing 271 impulse responses acquired in everyday places. Impulse responses are represented as audio (ideally wav) files in the given ir_path .","title":"ApplyImpulseResponse"},{"location":"waveform_transforms/apply_impulse_response/#applyimpulseresponse-api","text":"ir_path : Union[List[Path], List[str], str, Path] A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be impulse responses. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. lru_cache_size : int Default: 128 . Maximum size of the LRU cache for storing impulse response files in memory. leave_length_unchanged : bool Default: True . When set to True , the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input.","title":"ApplyImpulseResponse API"},{"location":"waveform_transforms/band_pass_filter/","text":"BandPassFilter Added in v0.18.0, updated in v0.21.0 Apply band-pass filtering to the input audio. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs). BandPassFilter API min_center_freq : float \u2022 unit: hertz Default: 200.0 . Minimum center frequency in hertz max_center_freq : float \u2022 unit: hertz Default: 4000.0 . Maximum center frequency in hertz min_bandwidth_fraction : float Default: 0.5 . Minimum bandwidth relative to center frequency max_bandwidth_fraction : float Default: 1.99 . Maximum bandwidth relative to center frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"BandPassFilter"},{"location":"waveform_transforms/band_pass_filter/#bandpassfilter","text":"Added in v0.18.0, updated in v0.21.0 Apply band-pass filtering to the input audio. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs).","title":"BandPassFilter"},{"location":"waveform_transforms/band_pass_filter/#bandpassfilter-api","text":"min_center_freq : float \u2022 unit: hertz Default: 200.0 . Minimum center frequency in hertz max_center_freq : float \u2022 unit: hertz Default: 4000.0 . Maximum center frequency in hertz min_bandwidth_fraction : float Default: 0.5 . Minimum bandwidth relative to center frequency max_bandwidth_fraction : float Default: 1.99 . Maximum bandwidth relative to center frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"BandPassFilter API"},{"location":"waveform_transforms/band_stop_filter/","text":"BandStopFilter Added in v0.21.0 Apply band-stop filtering to the input audio. Also known as notch filter or band reject filter. It relates to the frequency mask idea in the SpecAugment paper. Center frequency gets picked in mel space, so it is more aligned with human hearing, which is not linear. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs). BandStopFilter API min_center_freq : float \u2022 unit: hertz Default: 200.0 . Minimum center frequency in hertz max_center_freq : float \u2022 unit: hertz Default: 4000.0 . Maximum center frequency in hertz min_bandwidth_fraction : float Default: 0.5 . Minimum bandwidth relative to center frequency max_bandwidth_fraction : float Default: 1.99 . Maximum bandwidth relative to center frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"BandStopFilter"},{"location":"waveform_transforms/band_stop_filter/#bandstopfilter","text":"Added in v0.21.0 Apply band-stop filtering to the input audio. Also known as notch filter or band reject filter. It relates to the frequency mask idea in the SpecAugment paper. Center frequency gets picked in mel space, so it is more aligned with human hearing, which is not linear. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs).","title":"BandStopFilter"},{"location":"waveform_transforms/band_stop_filter/#bandstopfilter-api","text":"min_center_freq : float \u2022 unit: hertz Default: 200.0 . Minimum center frequency in hertz max_center_freq : float \u2022 unit: hertz Default: 4000.0 . Maximum center frequency in hertz min_bandwidth_fraction : float Default: 0.5 . Minimum bandwidth relative to center frequency max_bandwidth_fraction : float Default: 1.99 . Maximum bandwidth relative to center frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"BandStopFilter API"},{"location":"waveform_transforms/clip/","text":"Clip Added in v0.17.0 Clip audio by specified values. e.g. set a_min=-1.0 and a_max=1.0 to ensure that no samples in the audio exceed that extent. This can be relevant for avoiding integer overflow or underflow (which results in unintended wrap distortion that can sound horrible) when exporting to e.g. 16-bit PCM wav. Another way of ensuring that all values stay between -1.0 and 1.0 is to apply PeakNormalization . This transform is different from ClippingDistortion in that it takes fixed values for clipping instead of clipping a random percentile of the samples. Arguably, this transform is not very useful for data augmentation. Instead, think of it as a very cheap and harsh limiter (for samples that exceed the allotted extent) that can sometimes be useful at the end of a data augmentation pipeline. Clip API a_min : float Default: -1.0 . Minimum value for clipping. a_max : float Default: 1.0 . Maximum value for clipping. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Clip"},{"location":"waveform_transforms/clip/#clip","text":"Added in v0.17.0 Clip audio by specified values. e.g. set a_min=-1.0 and a_max=1.0 to ensure that no samples in the audio exceed that extent. This can be relevant for avoiding integer overflow or underflow (which results in unintended wrap distortion that can sound horrible) when exporting to e.g. 16-bit PCM wav. Another way of ensuring that all values stay between -1.0 and 1.0 is to apply PeakNormalization . This transform is different from ClippingDistortion in that it takes fixed values for clipping instead of clipping a random percentile of the samples. Arguably, this transform is not very useful for data augmentation. Instead, think of it as a very cheap and harsh limiter (for samples that exceed the allotted extent) that can sometimes be useful at the end of a data augmentation pipeline.","title":"Clip"},{"location":"waveform_transforms/clip/#clip-api","text":"a_min : float Default: -1.0 . Minimum value for clipping. a_max : float Default: 1.0 . Maximum value for clipping. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Clip API"},{"location":"waveform_transforms/clipping_distortion/","text":"ClippingDistortion Added in v0.8.0 Distort signal by clipping a random percentage of points The percentage of points that will be clipped is drawn from a uniform distribution between the two input parameters min_percentile_threshold and max_percentile_threshold . If for instance 30% is drawn, the samples are clipped if they're below the 15th or above the 85th percentile. ClippingDistortion API min_percentile_threshold : int Default: 0 . A lower bound on the total percent of samples that will be clipped max_percentile_threshold : int Default: 40 . An upper bound on the total percent of samples that will be clipped p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"ClippingDistortion"},{"location":"waveform_transforms/clipping_distortion/#clippingdistortion","text":"Added in v0.8.0 Distort signal by clipping a random percentage of points The percentage of points that will be clipped is drawn from a uniform distribution between the two input parameters min_percentile_threshold and max_percentile_threshold . If for instance 30% is drawn, the samples are clipped if they're below the 15th or above the 85th percentile.","title":"ClippingDistortion"},{"location":"waveform_transforms/clipping_distortion/#clippingdistortion-api","text":"min_percentile_threshold : int Default: 0 . A lower bound on the total percent of samples that will be clipped max_percentile_threshold : int Default: 40 . An upper bound on the total percent of samples that will be clipped p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"ClippingDistortion API"},{"location":"waveform_transforms/gain/","text":"Gain Added in v0.11.0 Multiply the audio by a random amplitude factor to reduce or increase the volume. This technique can help a model become somewhat invariant to the overall gain of the input audio. Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping Gain API min_gain_in_db : float \u2022 unit: Decibel Default: -12.0 . Minimum gain. max_gain_in_db : float \u2022 unit: Decibel Default: 12.0 . Maximum gain. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Gain"},{"location":"waveform_transforms/gain/#gain","text":"Added in v0.11.0 Multiply the audio by a random amplitude factor to reduce or increase the volume. This technique can help a model become somewhat invariant to the overall gain of the input audio. Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping","title":"Gain"},{"location":"waveform_transforms/gain/#gain-api","text":"min_gain_in_db : float \u2022 unit: Decibel Default: -12.0 . Minimum gain. max_gain_in_db : float \u2022 unit: Decibel Default: 12.0 . Maximum gain. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Gain API"},{"location":"waveform_transforms/gain_transition/","text":"GainTransition Added in v0.22.0 Gradually change the volume up or down over a random time span. Also known as fade in and fade out. The fade works on a logarithmic scale, which is natural to human hearing. The way this works is that it picks two gains: a first gain and a second gain. Then it picks a time range for the transition between those two gains. Note that this transition can start before the audio starts and/or end after the audio ends, so the output audio can start or end in the middle of a transition. The gain starts at the first gain and is held constant until the transition start. Then it transitions to the second gain. Then that gain is held constant until the end of the sound. GainTransition API min_gain_in_db : float \u2022 unit: Decibel Default: -24.0 . Minimum gain. max_gain_in_db : float \u2022 unit: Decibel Default: 6.0 . Maximum gain. min_duration : Union[float, int] \u2022 unit: see duration_unit Default: 0.2 . Minimum length of transition. max_duration : Union[float, int] \u2022 unit: see duration_unit Default: 6.0 . Maximum length of transition. duration_unit : str \u2022 choices: \"fraction\" , \"samples\" , \"seconds\" Default: \"seconds\" . Defines the unit of the value of min_duration and max_duration . \"fraction\" : Fraction of the total sound length \"samples\" : Number of audio samples \"seconds\" : Number of seconds p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"GainTransition"},{"location":"waveform_transforms/gain_transition/#gaintransition","text":"Added in v0.22.0 Gradually change the volume up or down over a random time span. Also known as fade in and fade out. The fade works on a logarithmic scale, which is natural to human hearing. The way this works is that it picks two gains: a first gain and a second gain. Then it picks a time range for the transition between those two gains. Note that this transition can start before the audio starts and/or end after the audio ends, so the output audio can start or end in the middle of a transition. The gain starts at the first gain and is held constant until the transition start. Then it transitions to the second gain. Then that gain is held constant until the end of the sound.","title":"GainTransition"},{"location":"waveform_transforms/gain_transition/#gaintransition-api","text":"min_gain_in_db : float \u2022 unit: Decibel Default: -24.0 . Minimum gain. max_gain_in_db : float \u2022 unit: Decibel Default: 6.0 . Maximum gain. min_duration : Union[float, int] \u2022 unit: see duration_unit Default: 0.2 . Minimum length of transition. max_duration : Union[float, int] \u2022 unit: see duration_unit Default: 6.0 . Maximum length of transition. duration_unit : str \u2022 choices: \"fraction\" , \"samples\" , \"seconds\" Default: \"seconds\" . Defines the unit of the value of min_duration and max_duration . \"fraction\" : Fraction of the total sound length \"samples\" : Number of audio samples \"seconds\" : Number of seconds p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"GainTransition API"},{"location":"waveform_transforms/high_pass_filter/","text":"HighPassFilter Added in v0.18.0, updated in v0.21.0 Apply high-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6db drop at cutoff). HighPassFilter API min_cutoff_freq : float \u2022 unit: hertz Default: 20.0 . Minimum cutoff frequency max_cutoff_freq : float \u2022 unit: hertz Default: 2400.0 . Maximum cutoff frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave). Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"HighPassFilter"},{"location":"waveform_transforms/high_pass_filter/#highpassfilter","text":"Added in v0.18.0, updated in v0.21.0 Apply high-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6db drop at cutoff).","title":"HighPassFilter"},{"location":"waveform_transforms/high_pass_filter/#highpassfilter-api","text":"min_cutoff_freq : float \u2022 unit: hertz Default: 20.0 . Minimum cutoff frequency max_cutoff_freq : float \u2022 unit: hertz Default: 2400.0 . Maximum cutoff frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave). Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"HighPassFilter API"},{"location":"waveform_transforms/high_shelf_filter/","text":"HighShelfFilter Added in v0.21.0 A high shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies above a certain center frequency. This transform applies a high-shelf filter at a specific center frequency in hertz. The gain at nyquist frequency is controlled by {min,max}_gain_db (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook HighShelfFilter API min_center_freq : float \u2022 unit: hertz Default: 300.0 . The minimum center frequency of the shelving filter max_center_freq : float \u2022 unit: hertz Default: 7500.0 . The maximum center frequency of the shelving filter min_gain_db : float \u2022 unit: Decibel Default: -18.0 . The minimum gain at the nyquist frequency max_gain_db : float \u2022 unit: Decibel Default: 18.0 . The maximum gain at the nyquist frequency min_q : float \u2022 range: (0.0, 1.0] Default: 0.1 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: (0.0, 1.0] Default: 0.999 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"HighShelfFilter"},{"location":"waveform_transforms/high_shelf_filter/#highshelffilter","text":"Added in v0.21.0 A high shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies above a certain center frequency. This transform applies a high-shelf filter at a specific center frequency in hertz. The gain at nyquist frequency is controlled by {min,max}_gain_db (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook","title":"HighShelfFilter"},{"location":"waveform_transforms/high_shelf_filter/#highshelffilter-api","text":"min_center_freq : float \u2022 unit: hertz Default: 300.0 . The minimum center frequency of the shelving filter max_center_freq : float \u2022 unit: hertz Default: 7500.0 . The maximum center frequency of the shelving filter min_gain_db : float \u2022 unit: Decibel Default: -18.0 . The minimum gain at the nyquist frequency max_gain_db : float \u2022 unit: Decibel Default: 18.0 . The maximum gain at the nyquist frequency min_q : float \u2022 range: (0.0, 1.0] Default: 0.1 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: (0.0, 1.0] Default: 0.999 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"HighShelfFilter API"},{"location":"waveform_transforms/lambda/","text":"Lambda Added in v0.26.0 Apply a user-defined transform (callable) to the signal. Lambda API transform : Callable A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. **kwargs Optional extra parameters passed to the callable transform","title":"Lambda"},{"location":"waveform_transforms/lambda/#lambda","text":"Added in v0.26.0 Apply a user-defined transform (callable) to the signal.","title":"Lambda"},{"location":"waveform_transforms/lambda/#lambda-api","text":"transform : Callable A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. **kwargs Optional extra parameters passed to the callable transform","title":"Lambda API"},{"location":"waveform_transforms/limiter/","text":"Limiter Added in v0.26.0 A simple audio limiter (dynamic range compression). Note: This transform also delays the signal by a fraction of the attack time. The threshold determines the audio level above which the limiter kicks in. The attack time is how quickly the limiter kicks in once the audio signal starts exceeding the threshold. The release time determines how quickly the limiter stops working after the signal drops below the threshold. Limiter API min_threshold_db : float \u2022 unit: Decibel Default: -24.0 . Minimum threshold max_threshold_db : float \u2022 unit: Decibel Default: -2.0 . Maximum threshold min_attack : float \u2022 unit: seconds Default: 0.0005 . Minimum attack time max_attack : float \u2022 unit: seconds Default: 0.025 . Maximum attack time min_release : float \u2022 unit: seconds Default: 0.05 . Minimum release time max_release : float \u2022 unit: seconds Default: 0.7 . Maximum release time threshold_mode : str \u2022 choices: \"relative_to_signal_peak\" , \"absolute\" Default: relative_to_signal_peak . \"relative_to_signal_peak\" means the threshold is relative to peak of the signal. \"absolute\" means the threshold is relative to 0 dBFS, so it doesn't depend on the peak of the signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Limiter"},{"location":"waveform_transforms/limiter/#limiter","text":"Added in v0.26.0 A simple audio limiter (dynamic range compression). Note: This transform also delays the signal by a fraction of the attack time. The threshold determines the audio level above which the limiter kicks in. The attack time is how quickly the limiter kicks in once the audio signal starts exceeding the threshold. The release time determines how quickly the limiter stops working after the signal drops below the threshold.","title":"Limiter"},{"location":"waveform_transforms/limiter/#limiter-api","text":"min_threshold_db : float \u2022 unit: Decibel Default: -24.0 . Minimum threshold max_threshold_db : float \u2022 unit: Decibel Default: -2.0 . Maximum threshold min_attack : float \u2022 unit: seconds Default: 0.0005 . Minimum attack time max_attack : float \u2022 unit: seconds Default: 0.025 . Maximum attack time min_release : float \u2022 unit: seconds Default: 0.05 . Minimum release time max_release : float \u2022 unit: seconds Default: 0.7 . Maximum release time threshold_mode : str \u2022 choices: \"relative_to_signal_peak\" , \"absolute\" Default: relative_to_signal_peak . \"relative_to_signal_peak\" means the threshold is relative to peak of the signal. \"absolute\" means the threshold is relative to 0 dBFS, so it doesn't depend on the peak of the signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Limiter API"},{"location":"waveform_transforms/loudness_normalization/","text":"LoudnessNormalization Added in v0.14.0 Apply a constant amount of gain to match a specific loudness (in LUFS). This is an implementation of ITU-R BS.1770-4. For an explanation on LUFS, see https://en.wikipedia.org/wiki/LUFS See also the following web pages for more info on audio loudness normalization: https://github.com/csteinmetz1/pyloudnorm https://en.wikipedia.org/wiki/Audio_normalization Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping LoudnessNormalization API min_lufs_in_db : float \u2022 unit: LUFS Default: -31.0 . Minimum loudness target max_lufs_in_db : float \u2022 unit: LUFS Default: -13.0 . Maximum loudness target p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LoudnessNormalization"},{"location":"waveform_transforms/loudness_normalization/#loudnessnormalization","text":"Added in v0.14.0 Apply a constant amount of gain to match a specific loudness (in LUFS). This is an implementation of ITU-R BS.1770-4. For an explanation on LUFS, see https://en.wikipedia.org/wiki/LUFS See also the following web pages for more info on audio loudness normalization: https://github.com/csteinmetz1/pyloudnorm https://en.wikipedia.org/wiki/Audio_normalization Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping","title":"LoudnessNormalization"},{"location":"waveform_transforms/loudness_normalization/#loudnessnormalization-api","text":"min_lufs_in_db : float \u2022 unit: LUFS Default: -31.0 . Minimum loudness target max_lufs_in_db : float \u2022 unit: LUFS Default: -13.0 . Maximum loudness target p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LoudnessNormalization API"},{"location":"waveform_transforms/low_pass_filter/","text":"LowPassFilter Added in v0.18.0, updated in v0.21.0 Apply low-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6db drop at cutoff). LowPassFilter API min_cutoff_freq : float \u2022 unit: hertz Default: 150.0 . Minimum cutoff frequency max_cutoff_freq : float \u2022 unit: hertz Default: 7500.0 . Maximum cutoff frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LowPassFilter"},{"location":"waveform_transforms/low_pass_filter/#lowpassfilter","text":"Added in v0.18.0, updated in v0.21.0 Apply low-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6db drop at cutoff).","title":"LowPassFilter"},{"location":"waveform_transforms/low_pass_filter/#lowpassfilter-api","text":"min_cutoff_freq : float \u2022 unit: hertz Default: 150.0 . Minimum cutoff frequency max_cutoff_freq : float \u2022 unit: hertz Default: 7500.0 . Maximum cutoff frequency min_rolloff : float \u2022 unit: Decibels/octave Default: 12 . Minimum filter roll-off (in dB/octave). Must be a multiple of 6 max_rolloff : float \u2022 unit: Decibels/octave Default: 24 . Maximum filter roll-off (in dB/octave) Must be a multiple of 6 zero_phase : bool Default: False . Whether filtering should be zero phase. When this is set to True it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is 2 times slower than in the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to True . p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LowPassFilter API"},{"location":"waveform_transforms/low_shelf_filter/","text":"LowShelfFilter Added in v0.21.0 A low shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies below a certain center frequency. This transform applies a low-shelf filter at a specific center frequency in hertz. The gain at DC frequency is controlled by {min,max}_gain_db (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook LowShelfFilter API min_center_freq : float \u2022 unit: hertz Default: 50.0 . The minimum center frequency of the shelving filter max_center_freq : float \u2022 unit: hertz Default: 4000.0 . The maximum center frequency of the shelving filter min_gain_db : float \u2022 unit: Decibel Default: -18.0 . The minimum gain at DC (0 hz) max_gain_db : float \u2022 unit: Decibel Default: 18.0 . The maximum gain at DC (0 hz) min_q : float \u2022 range: (0.0, 1.0] Default: 0.1 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: (0.0, 1.0] Default: 0.999 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LowShelfFilter"},{"location":"waveform_transforms/low_shelf_filter/#lowshelffilter","text":"Added in v0.21.0 A low shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies below a certain center frequency. This transform applies a low-shelf filter at a specific center frequency in hertz. The gain at DC frequency is controlled by {min,max}_gain_db (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook","title":"LowShelfFilter"},{"location":"waveform_transforms/low_shelf_filter/#lowshelffilter-api","text":"min_center_freq : float \u2022 unit: hertz Default: 50.0 . The minimum center frequency of the shelving filter max_center_freq : float \u2022 unit: hertz Default: 4000.0 . The maximum center frequency of the shelving filter min_gain_db : float \u2022 unit: Decibel Default: -18.0 . The minimum gain at DC (0 hz) max_gain_db : float \u2022 unit: Decibel Default: 18.0 . The maximum gain at DC (0 hz) min_q : float \u2022 range: (0.0, 1.0] Default: 0.1 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: (0.0, 1.0] Default: 0.999 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"LowShelfFilter API"},{"location":"waveform_transforms/mp3_compression/","text":"Mp3Compression Added in v0.12.0 Compress the audio using an MP3 encoder to lower the audio quality. This may help machine learning models deal with compressed, low-quality audio. This transform depends on either lameenc or pydub/ffmpeg. Note that bitrates below 32 kbps are only supported for low sample rates (up to 24000 hz). Note: When using the \"lameenc\" backend, the output may be slightly longer than the input due to the fact that the LAME encoder inserts some silence at the beginning of the audio. Warning: This transform writes to disk, so it may be slow. Mp3Compression API min_bitrate : int \u2022 unit: kbps \u2022 range: [8, 320] Default: 8 . Minimum bitrate in kbps max_bitrate : int \u2022 unit: kbps \u2022 range: [8, 320] Default: 64 . Maximum bitrate in kbps backend : str \u2022 choices: \"pydub\" , \"lameenc\" Default: \"pydub\" . \"pydub\" : May use ffmpeg under the hood. Pro: Seems to avoid introducing latency in the output. Con: Slightly slower than \"lameenc\" . \"lameenc\" : Pro: With this backend you can set the quality parameter in addition to the bitrate (although this parameter is not exposed in the audiomentations API yet). Con: Seems to introduce some silence at the start of the audio. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Mp3Compression"},{"location":"waveform_transforms/mp3_compression/#mp3compression","text":"Added in v0.12.0 Compress the audio using an MP3 encoder to lower the audio quality. This may help machine learning models deal with compressed, low-quality audio. This transform depends on either lameenc or pydub/ffmpeg. Note that bitrates below 32 kbps are only supported for low sample rates (up to 24000 hz). Note: When using the \"lameenc\" backend, the output may be slightly longer than the input due to the fact that the LAME encoder inserts some silence at the beginning of the audio. Warning: This transform writes to disk, so it may be slow.","title":"Mp3Compression"},{"location":"waveform_transforms/mp3_compression/#mp3compression-api","text":"min_bitrate : int \u2022 unit: kbps \u2022 range: [8, 320] Default: 8 . Minimum bitrate in kbps max_bitrate : int \u2022 unit: kbps \u2022 range: [8, 320] Default: 64 . Maximum bitrate in kbps backend : str \u2022 choices: \"pydub\" , \"lameenc\" Default: \"pydub\" . \"pydub\" : May use ffmpeg under the hood. Pro: Seems to avoid introducing latency in the output. Con: Slightly slower than \"lameenc\" . \"lameenc\" : Pro: With this backend you can set the quality parameter in addition to the bitrate (although this parameter is not exposed in the audiomentations API yet). Con: Seems to introduce some silence at the start of the audio. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Mp3Compression API"},{"location":"waveform_transforms/normalize/","text":"Normalize Added in v0.6.0 Apply a constant amount of gain, so that highest signal level present in the sound becomes 0 dBFS, i.e. the loudest level allowed if all samples must be between -1 and 1. Also known as peak normalization. Normalize API p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Normalize"},{"location":"waveform_transforms/normalize/#normalize","text":"Added in v0.6.0 Apply a constant amount of gain, so that highest signal level present in the sound becomes 0 dBFS, i.e. the loudest level allowed if all samples must be between -1 and 1. Also known as peak normalization.","title":"Normalize"},{"location":"waveform_transforms/normalize/#normalize-api","text":"p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Normalize API"},{"location":"waveform_transforms/padding/","text":"Padding Added in v0.23.0 Apply padding to the audio signal - take a fraction of the end or the start of the audio and replace that part with padding. This can be useful for preparing ML models with constant input length for padded inputs. Padding API mode : str \u2022 choices: \"silence\" , \"wrap\" , \"reflect\" Default: \"silence\" . Padding mode. min_fraction : float \u2022 range: [0.0, 1.0] Default: 0.01 . Minimum fraction of the signal duration to be padded max_fraction : float \u2022 range: [0.0, 1.0] Default: 0.7 . Maximum fraction of the signal duration to be padded pad_section : str \u2022 choices: \"start\" , \"end\" Default: \"end\" . Which part of the signal should be replaced with padding p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Padding"},{"location":"waveform_transforms/padding/#padding","text":"Added in v0.23.0 Apply padding to the audio signal - take a fraction of the end or the start of the audio and replace that part with padding. This can be useful for preparing ML models with constant input length for padded inputs.","title":"Padding"},{"location":"waveform_transforms/padding/#padding-api","text":"mode : str \u2022 choices: \"silence\" , \"wrap\" , \"reflect\" Default: \"silence\" . Padding mode. min_fraction : float \u2022 range: [0.0, 1.0] Default: 0.01 . Minimum fraction of the signal duration to be padded max_fraction : float \u2022 range: [0.0, 1.0] Default: 0.7 . Maximum fraction of the signal duration to be padded pad_section : str \u2022 choices: \"start\" , \"end\" Default: \"end\" . Which part of the signal should be replaced with padding p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Padding API"},{"location":"waveform_transforms/peaking_filter/","text":"PeakingFilter Added in v0.21.0 Add a biquad peaking filter transform PeakingFilter API min_center_freq : float \u2022 unit: hertz \u2022 range: [0.0, \u221e) Default: 50.0 . The minimum center frequency of the peaking filter max_center_freq : float \u2022 unit: hertz \u2022 range: [0.0, \u221e) Default: 7500.0 . The maximum center frequency of the peaking filter min_gain_db : float \u2022 unit: Decibel Default: -24.0 . The minimum gain at center frequency max_gain_db : float \u2022 unit: Decibel Default: 24.0 . The maximum gain at center frequency min_q : float \u2022 range: [0.0, \u221e) Default: 0.5 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: [0.0, \u221e) Default: 5.0 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PeakingFilter"},{"location":"waveform_transforms/peaking_filter/#peakingfilter","text":"Added in v0.21.0 Add a biquad peaking filter transform","title":"PeakingFilter"},{"location":"waveform_transforms/peaking_filter/#peakingfilter-api","text":"min_center_freq : float \u2022 unit: hertz \u2022 range: [0.0, \u221e) Default: 50.0 . The minimum center frequency of the peaking filter max_center_freq : float \u2022 unit: hertz \u2022 range: [0.0, \u221e) Default: 7500.0 . The maximum center frequency of the peaking filter min_gain_db : float \u2022 unit: Decibel Default: -24.0 . The minimum gain at center frequency max_gain_db : float \u2022 unit: Decibel Default: 24.0 . The maximum gain at center frequency min_q : float \u2022 range: [0.0, \u221e) Default: 0.5 . The minimum quality factor Q. The higher the Q, the steeper the transition band will be. max_q : float \u2022 range: [0.0, \u221e) Default: 5.0 . The maximum quality factor Q. The higher the Q, the steeper the transition band will be. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PeakingFilter API"},{"location":"waveform_transforms/pitch_shift/","text":"PitchShift Added in v0.4.0 Pitch shift the sound up or down without changing the tempo PitchShift API min_semitones : float \u2022 unit: semitones \u2022 range: [-12.0, 12.0] Default: -4.0 . Minimum semitones to shift. Negative number means shift down. max_semitones : float \u2022 unit: semitones \u2022 range: [-12.0, 12.0] Default: 4.0 . Maximum semitones to shift. Positive number means shift up. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PitchShift"},{"location":"waveform_transforms/pitch_shift/#pitchshift","text":"Added in v0.4.0 Pitch shift the sound up or down without changing the tempo","title":"PitchShift"},{"location":"waveform_transforms/pitch_shift/#pitchshift-api","text":"min_semitones : float \u2022 unit: semitones \u2022 range: [-12.0, 12.0] Default: -4.0 . Minimum semitones to shift. Negative number means shift down. max_semitones : float \u2022 unit: semitones \u2022 range: [-12.0, 12.0] Default: 4.0 . Maximum semitones to shift. Positive number means shift up. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PitchShift API"},{"location":"waveform_transforms/polarity_inversion/","text":"PolarityInversion Added in v0.11.0 Flip the audio samples upside-down, reversing their polarity. In other words, multiply the waveform by -1, so negative values become positive, and vice versa. The result will sound the same compared to the original when played back in isolation. However, when mixed with other audio sources, the result may be different. This waveform inversion technique is sometimes used for audio cancellation or obtaining the difference between two waveforms. However, in the context of audio data augmentation, this transform can be useful when training phase-aware machine learning models. PolarityInversion API p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PolarityInversion"},{"location":"waveform_transforms/polarity_inversion/#polarityinversion","text":"Added in v0.11.0 Flip the audio samples upside-down, reversing their polarity. In other words, multiply the waveform by -1, so negative values become positive, and vice versa. The result will sound the same compared to the original when played back in isolation. However, when mixed with other audio sources, the result may be different. This waveform inversion technique is sometimes used for audio cancellation or obtaining the difference between two waveforms. However, in the context of audio data augmentation, this transform can be useful when training phase-aware machine learning models.","title":"PolarityInversion"},{"location":"waveform_transforms/polarity_inversion/#polarityinversion-api","text":"p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"PolarityInversion API"},{"location":"waveform_transforms/post_gain/","text":"PostGain Added in v0.30.0 Gain up or down the audio after the given transform (or set of transforms) has processed the audio. There are several methods that determine how the audio should be gained. PostGain can be useful for compensating for any gain differences introduced by a (set of) transform(s), or for preventing clipping in the output. PostGain API transform : Callable[[np.ndarray, int], np.ndarray] A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. method : str \u2022 choices: \"same_rms\" , \"same_lufs\" or \"peak_normalize_always\" This parameter defines the method for choosing the post gain amount. \"same_rms\" : The sound gets post-gained so that the RMS (Root Mean Square) of the output matches the RMS of the input. \"same_lufs\" : The sound gets post-gained so that the LUFS (Loudness Units Full Scale) of the output matches the LUFS of the input. \"peak_normalize_always\" : The sound gets peak normalized (gained up or down so that the absolute value of the most extreme sample in the output is 1.0) \"peak_normalize_if_too_loud\" : The sound gets peak normalized if it is too loud (max absolute value greater than 1.0). This option can be useful for avoiding clipping.","title":"PostGain"},{"location":"waveform_transforms/post_gain/#postgain","text":"Added in v0.30.0 Gain up or down the audio after the given transform (or set of transforms) has processed the audio. There are several methods that determine how the audio should be gained. PostGain can be useful for compensating for any gain differences introduced by a (set of) transform(s), or for preventing clipping in the output.","title":"PostGain"},{"location":"waveform_transforms/post_gain/#postgain-api","text":"transform : Callable[[np.ndarray, int], np.ndarray] A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. method : str \u2022 choices: \"same_rms\" , \"same_lufs\" or \"peak_normalize_always\" This parameter defines the method for choosing the post gain amount. \"same_rms\" : The sound gets post-gained so that the RMS (Root Mean Square) of the output matches the RMS of the input. \"same_lufs\" : The sound gets post-gained so that the LUFS (Loudness Units Full Scale) of the output matches the LUFS of the input. \"peak_normalize_always\" : The sound gets peak normalized (gained up or down so that the absolute value of the most extreme sample in the output is 1.0) \"peak_normalize_if_too_loud\" : The sound gets peak normalized if it is too loud (max absolute value greater than 1.0). This option can be useful for avoiding clipping.","title":"PostGain API"},{"location":"waveform_transforms/resample/","text":"Resample Added in v0.8.0 Resample signal using librosa.core.resample To do downsampling only set both minimum and maximum sampling rate lower than original sampling rate and vice versa to do upsampling only. Resample API min_sample_rate : int Default: 8000 . Minimum sample rate max_sample_rate : int Default: 44100 . Maximum sample rate p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Resample"},{"location":"waveform_transforms/resample/#resample","text":"Added in v0.8.0 Resample signal using librosa.core.resample To do downsampling only set both minimum and maximum sampling rate lower than original sampling rate and vice versa to do upsampling only.","title":"Resample"},{"location":"waveform_transforms/resample/#resample-api","text":"min_sample_rate : int Default: 8000 . Minimum sample rate max_sample_rate : int Default: 44100 . Maximum sample rate p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Resample API"},{"location":"waveform_transforms/reverse/","text":"Reverse Added in v0.18.0 Reverse the audio. Also known as time inversion. Inversion of an audio track along its time axis relates to the random flip of an image, which is an augmentation technique that is widely used in the visual domain. This can be relevant in the context of audio classification. It was successfully applied in the paper AudioCLIP: Extending CLIP to Image, Text and Audio . Reverse API p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Reverse"},{"location":"waveform_transforms/reverse/#reverse","text":"Added in v0.18.0 Reverse the audio. Also known as time inversion. Inversion of an audio track along its time axis relates to the random flip of an image, which is an augmentation technique that is widely used in the visual domain. This can be relevant in the context of audio classification. It was successfully applied in the paper AudioCLIP: Extending CLIP to Image, Text and Audio .","title":"Reverse"},{"location":"waveform_transforms/reverse/#reverse-api","text":"p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Reverse API"},{"location":"waveform_transforms/room_simulator/","text":"RoomSimulator Added in v0.23.0 A ShoeBox Room Simulator. Simulates a cuboid of parametrized size and average surface absorption coefficient. It also includes a source and microphones in parametrized locations. Use it when you want a ton of synthetic room impulse responses of specific configurations characteristics or simply to quickly add reverb for augmentation purposes RoomSimulator API min_size_x : float \u2022 unit: meters Default: 3.6 . Minimum width (x coordinate) of the room in meters max_size_x : float \u2022 unit: meters Default: 5.6 . Maximum width of the room in meters min_size_y : float \u2022 unit: meters Default: 3.6 . Minimum depth (y coordinate) of the room in meters max_size_y : float \u2022 unit: meters Default: 3.9 . Maximum depth of the room in meters min_size_z : float \u2022 unit: meters Default: 2.4 . Minimum height (z coordinate) of the room in meters max_size_z : float \u2022 unit: meters Default: 3.0 . Maximum height of the room in meters min_absorption_value : float Default: 0.075 . Minimum absorption coefficient value. When calculation_mode is \"absorption\" it will set the given coefficient value for the surfaces of the room (walls, ceilings, and floor). This coefficient takes values between 0 (fully reflective surface) and 1 (fully absorbing surface). Example values (may differ!): Environment Coefficient value Studio with acoustic panels > 0.40 Office / Library ~ 0.15 Factory ~ 0.05 max_absorption_value : float Default: 0.4 . Maximum absorption coefficient value. See min_absorption_value for more info. min_target_rt60 : float \u2022 unit: seconds Default: 0.15 . Minimum target RT60. RT60 is defined as the measure of the time after the sound source ceases that it takes for the sound pressure level to reduce by 60 dB. When calculation_mode is \"rt60\" , it tries to set the absorption value of the surfaces of the room to achieve a target RT60 (in seconds). Note that this parameter changes only the materials (absorption coefficients) of the surfaces, not the dimension of the rooms. Example values (may differ!): Environment RT60 Recording studio 0.3 s Office 0.5 s Concert hall 1.5 s max_target_rt60 : float \u2022 unit: seconds Default: 0.8 . Maximum target RT60. See min_target_rt60 for more info. min_source_x : float \u2022 unit: meters Default: 0.1 . Minimum x location of the source max_source_x : float \u2022 unit: meters Default: 3.5 . Maximum x location of the source min_source_y : float \u2022 unit: meters Default: 0.1 . Minimum y location of the source max_source_x : float \u2022 unit: meters Default: 2.7 . Maximum y location of the source min_source_z : float \u2022 unit: meters Default: 1.0 . Minimum z location of the source max_source_x : float \u2022 unit: meters Default: 2.1 . Maximum z location of the source min_mic_distance : float \u2022 unit: meters Default: 0.15 . Minimum distance of the microphone from the source in meters max_mic_distance : float \u2022 unit: meters Default: 0.35 . Maximum distance of the microphone from the source in meters min_mic_azimuth : float \u2022 unit: radians Default: -math.pi . Minimum azimuth (angle around z axis) of the microphone relative to the source. max_mic_azimuth : float \u2022 unit: radians Default: math.pi . Maximum azimuth (angle around z axis) of the microphone relative to the source. min_mic_elevation : float \u2022 unit: radians Default: -math.pi . Minimum elevation of the microphone relative to the source, in radians. max_mic_elevation : float \u2022 unit: radians Default: math.pi . Maximum elevation of the microphone relative to the source, in radians. calculation_mode : str \u2022 choices: \"rt60\" , \"absorption\" Default: \"absorption\" . When set to \"absorption\" , it will create the room with surfaces based on min_absorption_value and max_absorption_value . If set to \"rt60\" it will try to assign surface materials that lead to a room impulse response with target rt60 given by min_target_rt60 and max_target_rt60 use_ray_tracing : bool Default: True . Whether to use ray_tracing or not (slower but much more accurate). Disable this if you need speed but do not really care for incorrect results. max_order : int \u2022 range: [1, \u221e) Default: 1 . Maximum order of reflections for the Image Source Model. E.g. a value of 1 will only add first order reflections while a value of 12 will add a diffuse reverberation tail. Warning Placing this higher than 11-12 will result in a very slow augmentation process when calculation_mode=\"rt60\" . Tip When using calculation_mode=\"rt60\" , keep it around 3-4 . leave_length_unchanged : bool Default: False . When set to True, the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input. padding : float \u2022 unit: meters Default: 0.1 . Minimum distance in meters between source or mic and the room walls, floor or ceiling. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. ray_tracing_options : Optional[Dict] Default: None . Options for the ray tracer. See set_ray_tracing here: https://github.com/LCAV/pyroomacoustics/blob/master/pyroomacoustics/room.py","title":"RoomSimulator"},{"location":"waveform_transforms/room_simulator/#roomsimulator","text":"Added in v0.23.0 A ShoeBox Room Simulator. Simulates a cuboid of parametrized size and average surface absorption coefficient. It also includes a source and microphones in parametrized locations. Use it when you want a ton of synthetic room impulse responses of specific configurations characteristics or simply to quickly add reverb for augmentation purposes","title":"RoomSimulator"},{"location":"waveform_transforms/room_simulator/#roomsimulator-api","text":"min_size_x : float \u2022 unit: meters Default: 3.6 . Minimum width (x coordinate) of the room in meters max_size_x : float \u2022 unit: meters Default: 5.6 . Maximum width of the room in meters min_size_y : float \u2022 unit: meters Default: 3.6 . Minimum depth (y coordinate) of the room in meters max_size_y : float \u2022 unit: meters Default: 3.9 . Maximum depth of the room in meters min_size_z : float \u2022 unit: meters Default: 2.4 . Minimum height (z coordinate) of the room in meters max_size_z : float \u2022 unit: meters Default: 3.0 . Maximum height of the room in meters min_absorption_value : float Default: 0.075 . Minimum absorption coefficient value. When calculation_mode is \"absorption\" it will set the given coefficient value for the surfaces of the room (walls, ceilings, and floor). This coefficient takes values between 0 (fully reflective surface) and 1 (fully absorbing surface). Example values (may differ!): Environment Coefficient value Studio with acoustic panels > 0.40 Office / Library ~ 0.15 Factory ~ 0.05 max_absorption_value : float Default: 0.4 . Maximum absorption coefficient value. See min_absorption_value for more info. min_target_rt60 : float \u2022 unit: seconds Default: 0.15 . Minimum target RT60. RT60 is defined as the measure of the time after the sound source ceases that it takes for the sound pressure level to reduce by 60 dB. When calculation_mode is \"rt60\" , it tries to set the absorption value of the surfaces of the room to achieve a target RT60 (in seconds). Note that this parameter changes only the materials (absorption coefficients) of the surfaces, not the dimension of the rooms. Example values (may differ!): Environment RT60 Recording studio 0.3 s Office 0.5 s Concert hall 1.5 s max_target_rt60 : float \u2022 unit: seconds Default: 0.8 . Maximum target RT60. See min_target_rt60 for more info. min_source_x : float \u2022 unit: meters Default: 0.1 . Minimum x location of the source max_source_x : float \u2022 unit: meters Default: 3.5 . Maximum x location of the source min_source_y : float \u2022 unit: meters Default: 0.1 . Minimum y location of the source max_source_x : float \u2022 unit: meters Default: 2.7 . Maximum y location of the source min_source_z : float \u2022 unit: meters Default: 1.0 . Minimum z location of the source max_source_x : float \u2022 unit: meters Default: 2.1 . Maximum z location of the source min_mic_distance : float \u2022 unit: meters Default: 0.15 . Minimum distance of the microphone from the source in meters max_mic_distance : float \u2022 unit: meters Default: 0.35 . Maximum distance of the microphone from the source in meters min_mic_azimuth : float \u2022 unit: radians Default: -math.pi . Minimum azimuth (angle around z axis) of the microphone relative to the source. max_mic_azimuth : float \u2022 unit: radians Default: math.pi . Maximum azimuth (angle around z axis) of the microphone relative to the source. min_mic_elevation : float \u2022 unit: radians Default: -math.pi . Minimum elevation of the microphone relative to the source, in radians. max_mic_elevation : float \u2022 unit: radians Default: math.pi . Maximum elevation of the microphone relative to the source, in radians. calculation_mode : str \u2022 choices: \"rt60\" , \"absorption\" Default: \"absorption\" . When set to \"absorption\" , it will create the room with surfaces based on min_absorption_value and max_absorption_value . If set to \"rt60\" it will try to assign surface materials that lead to a room impulse response with target rt60 given by min_target_rt60 and max_target_rt60 use_ray_tracing : bool Default: True . Whether to use ray_tracing or not (slower but much more accurate). Disable this if you need speed but do not really care for incorrect results. max_order : int \u2022 range: [1, \u221e) Default: 1 . Maximum order of reflections for the Image Source Model. E.g. a value of 1 will only add first order reflections while a value of 12 will add a diffuse reverberation tail. Warning Placing this higher than 11-12 will result in a very slow augmentation process when calculation_mode=\"rt60\" . Tip When using calculation_mode=\"rt60\" , keep it around 3-4 . leave_length_unchanged : bool Default: False . When set to True, the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input. padding : float \u2022 unit: meters Default: 0.1 . Minimum distance in meters between source or mic and the room walls, floor or ceiling. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform. ray_tracing_options : Optional[Dict] Default: None . Options for the ray tracer. See set_ray_tracing here: https://github.com/LCAV/pyroomacoustics/blob/master/pyroomacoustics/room.py","title":"RoomSimulator API"},{"location":"waveform_transforms/seven_band_parametric_eq/","text":"SevenBandParametricEQ Added in v0.24.0 Adjust the volume of different frequency bands. This transform is a 7-band parametric equalizer - a combination of one low shelf filter, five peaking filters and one high shelf filter, all with randomized gains, Q values and center frequencies. Because this transform changes the timbre, but keeps the overall \"class\" of the sound the same (depending on application), it can be used for data augmentation to make ML models more robust to various frequency spectrums. Many things can affect the spectrum, for example: the nature and quality of the sound source room acoustics any objects between the microphone and the sound source microphone type/model the distance between the sound source and the microphone The seven bands have center frequencies picked in the following ranges (min-max): 42-95 hz 91-204 hz 196-441 hz 421-948 hz 909-2045 hz 1957-4404 hz 4216-9486 hz SevenBandParametricEQ API min_gain_db : float \u2022 unit: Decibel Default: -12.0 . Minimum number of dB to cut or boost a band max_gain_db : float \u2022 unit: decibel Default: 12.0 . Maximum number of dB to cut or boost a band p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"SevenBandParametricEQ"},{"location":"waveform_transforms/seven_band_parametric_eq/#sevenbandparametriceq","text":"Added in v0.24.0 Adjust the volume of different frequency bands. This transform is a 7-band parametric equalizer - a combination of one low shelf filter, five peaking filters and one high shelf filter, all with randomized gains, Q values and center frequencies. Because this transform changes the timbre, but keeps the overall \"class\" of the sound the same (depending on application), it can be used for data augmentation to make ML models more robust to various frequency spectrums. Many things can affect the spectrum, for example: the nature and quality of the sound source room acoustics any objects between the microphone and the sound source microphone type/model the distance between the sound source and the microphone The seven bands have center frequencies picked in the following ranges (min-max): 42-95 hz 91-204 hz 196-441 hz 421-948 hz 909-2045 hz 1957-4404 hz 4216-9486 hz","title":"SevenBandParametricEQ"},{"location":"waveform_transforms/seven_band_parametric_eq/#sevenbandparametriceq-api","text":"min_gain_db : float \u2022 unit: Decibel Default: -12.0 . Minimum number of dB to cut or boost a band max_gain_db : float \u2022 unit: decibel Default: 12.0 . Maximum number of dB to cut or boost a band p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"SevenBandParametricEQ API"},{"location":"waveform_transforms/shift/","text":"Shift Added in v0.5.0 Shift the samples forwards or backwards, with or without rollover Shift API min_fraction : float \u2022 range: [-1, 1] Default: -0.5 . Minimum fraction of total sound length to shift. max_fraction : float \u2022 range: [-1, 1] Default: 0.5 . Maximum fraction of total sound length to shift. rollover : bool Default: True . When set to True , samples that roll beyond the first or last position are re-introduced at the last or first. When set to False , samples that roll beyond the first or last position are discarded. In other words, rollover=False results in an empty space (with zeroes). fade : bool Default: False . When set to True , there will be a short fade in and/or out at the \"stitch\" (that was the start or the end of the audio before the shift). This can smooth out an unwanted abrupt change between two consecutive samples (which sounds like a transient/click/pop). fade_duration : float \u2022 unit: seconds Default: 0.01 . If fade=True , then this is the duration of the fade in seconds. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Shift"},{"location":"waveform_transforms/shift/#shift","text":"Added in v0.5.0 Shift the samples forwards or backwards, with or without rollover","title":"Shift"},{"location":"waveform_transforms/shift/#shift-api","text":"min_fraction : float \u2022 range: [-1, 1] Default: -0.5 . Minimum fraction of total sound length to shift. max_fraction : float \u2022 range: [-1, 1] Default: 0.5 . Maximum fraction of total sound length to shift. rollover : bool Default: True . When set to True , samples that roll beyond the first or last position are re-introduced at the last or first. When set to False , samples that roll beyond the first or last position are discarded. In other words, rollover=False results in an empty space (with zeroes). fade : bool Default: False . When set to True , there will be a short fade in and/or out at the \"stitch\" (that was the start or the end of the audio before the shift). This can smooth out an unwanted abrupt change between two consecutive samples (which sounds like a transient/click/pop). fade_duration : float \u2022 unit: seconds Default: 0.01 . If fade=True , then this is the duration of the fade in seconds. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Shift API"},{"location":"waveform_transforms/tanh_distortion/","text":"TanhDistortion Added in v0.19.0 Apply tanh (hyperbolic tangent) distortion to the audio. This technique is sometimes used for adding distortion to guitar recordings. The tanh() function can give a rounded \"soft clipping\" kind of distortion, and the distortion amount is proportional to the loudness of the input and the pre-gain. Tanh is symmetric, so the positive and negative parts of the signal are squashed in the same way. This transform can be useful as data augmentation because it adds harmonics. In other words, it changes the timbre of the sound. See this page for examples: http://gdsp.hf.ntnu.no/lessons/3/17/ Input-output example In this example we apply tanh distortion with the \"distortion amount\" (think of it as a knob that goes from 0 to 1) set to 0.25 Input sound Transformed sound Usage example from audiomentations import TanhDistortion transform = TanhDistortion ( min_distortion = 0.01 , max_distortion = 0.7 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) TanhDistortion API min_distortion : float \u2022 range: [0.0, 1.0] Default: 0.01 . Minimum \"amount\" of distortion to apply to the signal. max_distortion : float \u2022 range: [0.0, 1.0] Default: 0.7 . Maximum \"amount\" of distortion to apply to the signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TanhDistortion"},{"location":"waveform_transforms/tanh_distortion/#tanhdistortion","text":"Added in v0.19.0 Apply tanh (hyperbolic tangent) distortion to the audio. This technique is sometimes used for adding distortion to guitar recordings. The tanh() function can give a rounded \"soft clipping\" kind of distortion, and the distortion amount is proportional to the loudness of the input and the pre-gain. Tanh is symmetric, so the positive and negative parts of the signal are squashed in the same way. This transform can be useful as data augmentation because it adds harmonics. In other words, it changes the timbre of the sound. See this page for examples: http://gdsp.hf.ntnu.no/lessons/3/17/","title":"TanhDistortion"},{"location":"waveform_transforms/tanh_distortion/#input-output-example","text":"In this example we apply tanh distortion with the \"distortion amount\" (think of it as a knob that goes from 0 to 1) set to 0.25 Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/tanh_distortion/#usage-example","text":"from audiomentations import TanhDistortion transform = TanhDistortion ( min_distortion = 0.01 , max_distortion = 0.7 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/tanh_distortion/#tanhdistortion-api","text":"min_distortion : float \u2022 range: [0.0, 1.0] Default: 0.01 . Minimum \"amount\" of distortion to apply to the signal. max_distortion : float \u2022 range: [0.0, 1.0] Default: 0.7 . Maximum \"amount\" of distortion to apply to the signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TanhDistortion API"},{"location":"waveform_transforms/time_mask/","text":"TimeMask Added in v0.7.0 Make a randomly chosen part of the audio silent. Inspired by https://arxiv.org/pdf/1904.08779.pdf Input-output example Here we silence a part of a speech recording. Input sound Transformed sound Usage example from audiomentations import TimeMask transform = TimeMask ( min_band_part = 0.1 , max_band_part = 0.15 , fade = True , p = 1.0 , ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) TimeMask API min_band_part : float \u2022 range: [0.0, 1.0] Default: 0.0 . Minimum length of the silent part as a fraction of the total sound length. max_band_part : float \u2022 range: [0.0, 1.0] Default: 0.5 . Maximum length of the silent part as a fraction of the total sound length. fade : bool Default: False . When set to True , add a linear fade in and fade out of the silent part. This can smooth out an unwanted abrupt change between two consecutive samples (which sounds like a transient/click/pop). p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TimeMask"},{"location":"waveform_transforms/time_mask/#timemask","text":"Added in v0.7.0 Make a randomly chosen part of the audio silent. Inspired by https://arxiv.org/pdf/1904.08779.pdf","title":"TimeMask"},{"location":"waveform_transforms/time_mask/#input-output-example","text":"Here we silence a part of a speech recording. Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/time_mask/#usage-example","text":"from audiomentations import TimeMask transform = TimeMask ( min_band_part = 0.1 , max_band_part = 0.15 , fade = True , p = 1.0 , ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/time_mask/#timemask-api","text":"min_band_part : float \u2022 range: [0.0, 1.0] Default: 0.0 . Minimum length of the silent part as a fraction of the total sound length. max_band_part : float \u2022 range: [0.0, 1.0] Default: 0.5 . Maximum length of the silent part as a fraction of the total sound length. fade : bool Default: False . When set to True , add a linear fade in and fade out of the silent part. This can smooth out an unwanted abrupt change between two consecutive samples (which sounds like a transient/click/pop). p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TimeMask API"},{"location":"waveform_transforms/time_stretch/","text":"TimeStretch Added in v0.2.0 Change the speed or duration of the signal without changing the pitch. This transform employs librosa.effects.time_stretch under the hood to achieve the effect. Input-output example In this example we speed up a sound by 25%. This corresponds to a rate of 1.25. Input sound Transformed sound Usage example from audiomentations import TimeStretch transform = TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , leave_length_unchanged = True , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) TimeStretch API min_rate : float \u2022 range: [0.1, 10.0] Default: 0.8 . Minimum rate of change of total duration of the signal. A rate below 1 means the audio is slowed down. max_rate : float \u2022 range: [0.1, 10.0] Default: 1.25 . Maximum rate of change of total duration of the signal. A rate greater than 1 means the audio is sped up. leave_length_unchanged : bool Default: True . The rate changes the duration and effects the samples. This flag is used to keep the total length of the generated output to be same as that of the input signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TimeStretch"},{"location":"waveform_transforms/time_stretch/#timestretch","text":"Added in v0.2.0 Change the speed or duration of the signal without changing the pitch. This transform employs librosa.effects.time_stretch under the hood to achieve the effect.","title":"TimeStretch"},{"location":"waveform_transforms/time_stretch/#input-output-example","text":"In this example we speed up a sound by 25%. This corresponds to a rate of 1.25. Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/time_stretch/#usage-example","text":"from audiomentations import TimeStretch transform = TimeStretch ( min_rate = 0.8 , max_rate = 1.25 , leave_length_unchanged = True , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/time_stretch/#timestretch-api","text":"min_rate : float \u2022 range: [0.1, 10.0] Default: 0.8 . Minimum rate of change of total duration of the signal. A rate below 1 means the audio is slowed down. max_rate : float \u2022 range: [0.1, 10.0] Default: 1.25 . Maximum rate of change of total duration of the signal. A rate greater than 1 means the audio is sped up. leave_length_unchanged : bool Default: True . The rate changes the duration and effects the samples. This flag is used to keep the total length of the generated output to be same as that of the input signal. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"TimeStretch API"},{"location":"waveform_transforms/trim/","text":"Trim Added in v0.7.0 Trim leading and trailing silence from an audio signal using librosa.effects.trim . It considers threshold (in decibels) below reference defined in parameter top_db as silence. Input-output example In this example we remove silence from the start and end, using the default top_db parameter value Input sound Transformed sound Usage example from audiomentations import Trim transform = Trim ( top_db = 30.0 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 ) Trim API top_db : float \u2022 unit: Decibel Default: 30.0 . The threshold value (in decibels) below which to consider silence and trim. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Trim"},{"location":"waveform_transforms/trim/#trim","text":"Added in v0.7.0 Trim leading and trailing silence from an audio signal using librosa.effects.trim . It considers threshold (in decibels) below reference defined in parameter top_db as silence.","title":"Trim"},{"location":"waveform_transforms/trim/#input-output-example","text":"In this example we remove silence from the start and end, using the default top_db parameter value Input sound Transformed sound","title":"Input-output example"},{"location":"waveform_transforms/trim/#usage-example","text":"from audiomentations import Trim transform = Trim ( top_db = 30.0 , p = 1.0 ) augmented_sound = transform ( my_waveform_ndarray , sample_rate = 16000 )","title":"Usage example"},{"location":"waveform_transforms/trim/#trim-api","text":"top_db : float \u2022 unit: Decibel Default: 30.0 . The threshold value (in decibels) below which to consider silence and trim. p : float \u2022 range: [0.0, 1.0] Default: 0.5 . The probability of applying this transform.","title":"Trim API"}]}